{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result figures for *Enhanced spatio-temporal electric load forecasts with less data using active deep learning*\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "1. Import and test results\n",
    "2. Numerical results\n",
    "3. Space and time selection\n",
    "4. Budget vs. accuracy\n",
    "5. Training and validation losses against unqueried candidates\n",
    "6. Validation losses against all candidates\n",
    "7. Query sequence importance\n",
    "8. Exemplar predictions\n",
    "9. Manuscript: Results summary\n",
    "10. Manuscript: Data selection maps\n",
    "\n",
    "In this notebook session, we summarize and visualize the results of our experiments. First test if all numerical results were computed with the same hyper parameters. Next, we plot our results and exemplar predictions so as to visually see and evaluate their meaning. Lastly, we create figures for our manuscript from experiments that best visualize our findings. We start with importing a number of packages that we use throughout this notebook session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set some parameters ###\n",
    "\n",
    "# choose which results dataset you want to process\n",
    "profile_set = 'profiles_100'\n",
    "\n",
    "# prediction types to consider\n",
    "PRED_TYPE_LIST = [\n",
    "    'spatial',\n",
    "    'temporal',\n",
    "    'spatio-temporal'\n",
    "]\n",
    "\n",
    "# parameter constellations to consider\n",
    "PARAMETER_LIST = [\n",
    "    'delta0_valup0', \n",
    "    'delta0_valup1', \n",
    "    'delta1_valup0', \n",
    "    'delta1_valup1'\n",
    "]\n",
    "\n",
    "\n",
    "# choose which AL variables to plot. Choose from 'X_t', 'X_s1', 'X_st', 'X_joint', 'X_(t,s)', 'Y_(t,s)'\n",
    "AL_VARIABLES = [\n",
    "#    'X_t', \n",
    "#    'X_s1', \n",
    "    'X_st', \n",
    "    'X_(t,s)', \n",
    "    'Y_hat_(t,s)', \n",
    "    'Y_(t,s)'\n",
    "]\n",
    "\n",
    "\n",
    "# choose which AL variables to plot. Choose from 'X_t', 'X_s1', 'X_st', 'X_joint', 'X_(t,s)', 'Y_(t,s)'\n",
    "AL_VARIANTS = [\n",
    "    'rnd d_c', \n",
    "    'max d_c', \n",
    "    'min d_c', \n",
    "    'avg d_c'\n",
    "]\n",
    "\n",
    "\n",
    "# create figure sub title list\n",
    "fig_title_list = [\n",
    "    'a.', 'b.', 'c.', 'd.', 'e.', 'f.', 'g.', 'h.',\n",
    "    'i.', 'j.', 'k.', 'l.', 'm.', 'n.', 'o.', 'p.',\n",
    "    'q.', 'r.', 's.', 't.', 'u.', 'v.', 'w.', 'x.'\n",
    "]\n",
    "\n",
    "# set width\n",
    "WIDTH_FACTOR = 8\n",
    "\n",
    "# set universal fontsize\n",
    "FONTSIZE = 20\n",
    "\n",
    "### Import packages ###\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "### Provide import paths and file names ###\n",
    "\n",
    "# path to results folder\n",
    "path_to_results = '../results/' + profile_set + '/'\n",
    "\n",
    "# path to initially trained encoders and prediction model\n",
    "path_to_encoders = path_to_results + 'encoder weights/'\n",
    "\n",
    "# path to numeric result values\n",
    "path_to_values = path_to_results + 'values/'\n",
    "\n",
    "# path to unseen test samples\n",
    "path_to_samples = path_to_results + 'samples/'\n",
    "\n",
    "# path to models \n",
    "path_to_models = path_to_results + 'models/'\n",
    "\n",
    "# individual file names\n",
    "hyper_filename = 'hyper.csv'\n",
    "results_filename = 'results.csv'\n",
    "seqimportance_filename = 'sequence_importance.csv'\n",
    "spacetime_selection_filename = 'spacetime_selection.csv'\n",
    "budgetaccuracy_filename = 'budget_vs_accuracy.csv'\n",
    "\n",
    "initial_model_filename = 'initial.h5'\n",
    "PL_model_filename = 'PL.h5'\n",
    "\n",
    "### Provide export paths and file names ###\n",
    "\n",
    "# path to saving result figures\n",
    "path_to_saving_figures = path_to_results + 'figures/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_figures):\n",
    "    os.mkdir(path_to_saving_figures)\n",
    "\n",
    "# path to subfolder for saving spacetime point selection\n",
    "path_to_saving_spacetime = path_to_saving_figures + 'space-time selection/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_spacetime):\n",
    "    os.mkdir(path_to_saving_spacetime)\n",
    "    \n",
    "# path to subfolder for saving budgetvsaccuracy\n",
    "path_to_saving_budgetvsaccuracy = path_to_saving_figures + 'budget vs accuracy/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_budgetvsaccuracy):\n",
    "    os.mkdir(path_to_saving_budgetvsaccuracy)\n",
    "    \n",
    "# path to subfolder for saving lossesvsunqueried\n",
    "path_to_saving_lossesvsunqueried = path_to_saving_figures + 'training vs validation losses/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_lossesvsunqueried):\n",
    "    os.mkdir(path_to_saving_lossesvsunqueried)\n",
    "    \n",
    "# path to subfolder for saving lossesvsall\n",
    "path_to_saving_lossesvsall = path_to_saving_figures + 'validation against all/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_lossesvsall):\n",
    "    os.mkdir(path_to_saving_lossesvsall)\n",
    "    \n",
    "# path to subfolder for saving seqimportance\n",
    "path_to_saving_seqimportance = path_to_saving_figures + 'sequence importance/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_seqimportance):\n",
    "    os.mkdir(path_to_saving_seqimportance)\n",
    "    \n",
    "# path to subfolder for saving exemplar predictions point selection\n",
    "path_to_exemplar_predictions = path_to_saving_figures + 'exemplar predictions/'\n",
    "\n",
    "if not os.path.exists(path_to_exemplar_predictions):\n",
    "    os.mkdir(path_to_exemplar_predictions)\n",
    "    \n",
    "# path to subfolder for saving manuscript figure ADL data selection\n",
    "path_to_ADL_selection = path_to_saving_figures + 'ADL selection/'\n",
    "\n",
    "if not os.path.exists(path_to_ADL_selection):\n",
    "    os.mkdir(path_to_ADL_selection)\n",
    "    \n",
    "# path to subfolder for saving manuscript figure ADL data selection\n",
    "path_to_summary_results = path_to_saving_figures + 'summary results/'\n",
    "\n",
    "if not os.path.exists(path_to_summary_results):\n",
    "    os.mkdir(path_to_summary_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Space and time selection\n",
    "\n",
    "Here, we visualize which points in time and space were queried during the experiments by our active learning and passive learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "# define some hyper for plots\n",
    "n_iter_plot = 10\n",
    "n_meshes_surface = 10\n",
    "\n",
    "# import building meta data\n",
    "path_to_building_meta = '../data/private/' + profile_set + '/meta/meta buildings.csv'\n",
    "building_meta = pd.read_csv(path_to_building_meta)\n",
    "\n",
    "def create_bottom_plot(first_colname, df_initial_sensors):\n",
    "    \n",
    "    ax.set_title(first_colname)\n",
    "\n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df_initial_sensors['building lat'].min()\n",
    "    max_lat = df_initial_sensors['building lat'].max() \n",
    "    min_long = df_initial_sensors['building long'].min()\n",
    "    max_long = df_initial_sensors['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    map_height = 0\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df_initial_sensors['building long'], \n",
    "        df_initial_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    ) \n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(map_height)\n",
    "    \n",
    "def create_plot(time_data, df, df_new_sensors):\n",
    "    \n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df['building lat'].min()\n",
    "    max_lat = df['building lat'].max() \n",
    "    min_long = df['building long'].min()\n",
    "    max_long = df['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    # update max time point\n",
    "    min_time_point, max_time_point = min(time_data), max(time_data)\n",
    "    map_height = max_time_point/3 * (1 + 3* iteration/n_iter_plot)\n",
    "    shifting_time = max_time_point - map_height\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df['building long'], \n",
    "        df['building lat'], \n",
    "        time_data - shifting_time, \n",
    "        c=time_data, alpha=0.7\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df_new_sensors['building long'], \n",
    "        df_new_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(min_time_point - shifting_time, max_time_point)\n",
    "    \n",
    "    \n",
    "def customize_plot(iteration=None):\n",
    "    \n",
    "    # set angle\n",
    "    ax.view_init(30, 103)\n",
    "    \n",
    "    # Get rid of the panes\n",
    "    ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "\n",
    "    # Get rid of the ticks\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # Add the labels\n",
    "    ax.set_xlabel('longitude' )\n",
    "    ax.set_ylabel('latitude')\n",
    "    ax.set_zlabel('time')\n",
    "\n",
    "    # shift time (z) axis\n",
    "    tmp_planes = ax.zaxis._PLANES \n",
    "    ax.zaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    # shift lat (y) axis\n",
    "    ax.yaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # set subplot titles\n",
    "    if iteration is not None:\n",
    "        ax.set_title('iteration {}'.format(iteration+1))\n",
    "\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        spacetime_result = spacetime_selection_list[result_index_counter]\n",
    "\n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        for AL_variable in AL_VARIABLES:\n",
    "            \n",
    "            for AL_variant in AL_VARIANTS:\n",
    "        \n",
    "                # create figure\n",
    "                fig = plt.figure(figsize=(16, (n_iter_plot+1) * 8))\n",
    "\n",
    "                # set the fontsize for figures\n",
    "                mpl.rcParams.update({'font.size': 16}) #FONTSIZE\n",
    "\n",
    "                colname_initial_sensors = '{} - initial sensors'.format(pred_type)\n",
    "                intial_sensors = spacetime_result[colname_initial_sensors]\n",
    "                df_initial_sensors = pd.DataFrame({'building ID':intial_sensors})\n",
    "                df_initial_sensors = df_initial_sensors.merge(building_meta, on='building ID', how='left')\n",
    "                \n",
    "                plot_counter= 1\n",
    "                ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                create_bottom_plot(\n",
    "                    'Active deep learning (ADL) \\n iteration 0',\n",
    "                    df_initial_sensors\n",
    "                )\n",
    "                customize_plot()\n",
    "                plot_counter += 1\n",
    "                ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                create_bottom_plot(\n",
    "                    'Passive deep learning (PDL) \\n iteration 0',\n",
    "                    df_initial_sensors\n",
    "                )\n",
    "                customize_plot()\n",
    "                plot_counter += 1\n",
    "                old_senors_AL_set = set(intial_sensors)\n",
    "                old_senors_PL_set = set(intial_sensors)\n",
    "                for iteration in range(n_iter_plot):\n",
    "\n",
    "                    # create column names\n",
    "                    colname_AL_times = '{} {} {} - iter {} time'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    colname_AL_spaces = '{} {} {} - iter {} space'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    colname_PL_times = '{} None PL - iter {} time'.format(pred_type, iteration)\n",
    "                    colname_PL_spaces = '{} None PL - iter {} space'.format(pred_type, iteration)\n",
    "                    \n",
    "                    ### Plot AL results on left column ###\n",
    "                    \n",
    "                    # get data\n",
    "                    space_data_AL = spacetime_result[colname_AL_spaces]\n",
    "                    time_data_AL = spacetime_result[colname_AL_times]\n",
    "                    space_data_PL = spacetime_result[colname_PL_spaces]\n",
    "                    time_data_PL = spacetime_result[colname_PL_times]\n",
    "\n",
    "                    # get new sensors and set old sensors\n",
    "                    new_sensors_AL_set = set(space_data_AL).union(old_senors_AL_set)\n",
    "                    new_sensors_PL_set = set(space_data_PL).union(old_senors_PL_set)\n",
    "                    new_sensors_AL_list = list(new_sensors_AL_set - old_senors_AL_set)\n",
    "                    new_sensors_PL_list = list(new_sensors_PL_set - old_senors_PL_set)\n",
    "                    old_senors_AL_set = new_sensors_AL_set\n",
    "                    old_senors_PL_set = new_sensors_PL_set\n",
    "                    \n",
    "                    # assign lat and long to building IDs\n",
    "                    df_AL = pd.DataFrame({'building ID':space_data_AL})\n",
    "                    df_AL = df_AL.merge(building_meta, on='building ID', how='left')\n",
    "                    df_PL = pd.DataFrame({'building ID':space_data_PL})\n",
    "                    df_PL = df_PL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    df_new_sensors_AL = pd.DataFrame({'building ID':new_sensors_AL_list})\n",
    "                    df_new_sensors_AL = df_new_sensors_AL.merge(building_meta, on='building ID', how='left')\n",
    "                    df_new_sensors_PL = pd.DataFrame({'building ID':new_sensors_PL_list})\n",
    "                    df_new_sensors_PL = df_new_sensors_PL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    # AL temporal scatter plot\n",
    "                    ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                    create_plot(time_data_AL, df_AL, df_new_sensors_AL)\n",
    "                    customize_plot(iteration)\n",
    "                    plot_counter += 1\n",
    "\n",
    "                    # PL temporal scatter plot\n",
    "                    ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                    create_plot(time_data_PL, df_PL, df_new_sensors_PL)\n",
    "                    customize_plot(iteration)\n",
    "                    plot_counter+= 1\n",
    "\n",
    "\n",
    "                # create saving paths \n",
    "                saving_path = (\n",
    "                    path_to_saving_spacetime \n",
    "                    + pred_type\n",
    "                    + ' '\n",
    "                    + parameter\n",
    "                    + ' '\n",
    "                    + AL_variable\n",
    "                    + ' '\n",
    "                    + AL_variant\n",
    "                    + '.pdf'\n",
    "                )\n",
    "\n",
    "                # create a legend\n",
    "                legend_elements = [\n",
    "                    Line2D([0], [0], marker='o', color='w', markerfacecolor='b', markersize=10, label='query in space-time'),\n",
    "                    Line2D([0], [0], marker='X', color='w', markerfacecolor='r', markersize=15, label='new sensor in space')\n",
    "                ]\n",
    "\n",
    "                # set layout tight\n",
    "                fig.tight_layout()\n",
    "\n",
    "                fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5,0.99))\n",
    "\n",
    "                # save figures\n",
    "                fig.savefig(saving_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Budget vs. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "for AL_variable in AL_VARIABLES:\n",
    "    for AL_variant in AL_VARIANTS:\n",
    "        \n",
    "        # set the fontsize for figures\n",
    "        mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "        fig, ax = plt.subplots(\n",
    "            len(PRED_TYPE_LIST), \n",
    "            2, \n",
    "            figsize=(\n",
    "                20, \n",
    "                8 * len(PRED_TYPE_LIST)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # set plot_counter for subplot title setting\n",
    "        plot_counter = 0\n",
    "\n",
    "        # create a counter over the list of numeric results\n",
    "        result_index_counter = 0\n",
    "\n",
    "        # iterate over all considered prediction types\n",
    "        for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "\n",
    "            # iterate over all considered parameter constellations\n",
    "            for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "\n",
    "                delta = int(parameter[5])\n",
    "                valup = int(parameter[12])\n",
    "\n",
    "                # skip cases where we validate against queried data too\n",
    "                if valup == 0:\n",
    "                    # increment result index counter\n",
    "                    result_index_counter += 1\n",
    "                    continue\n",
    "\n",
    "                # get results df corresponding to currently iterated parameter and pred_type\n",
    "                budgetaccuracy = budgetaccuracy_list[result_index_counter]\n",
    "\n",
    "                # increment result index counter\n",
    "                result_index_counter += 1\n",
    "\n",
    "                # create the column name for PL lossess\n",
    "                col_name_data = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'data'\n",
    "                )\n",
    "                col_name_sensors = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'sensors'\n",
    "                )\n",
    "                col_name_streamtimes = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'streamtimes'\n",
    "                )\n",
    "                col_name_accuracy = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'accuracy'\n",
    "                )\n",
    "\n",
    "                # get PL results\n",
    "                PL_data = np.append(0, budgetaccuracy[col_name_data].values)\n",
    "                PL_accuracy = np.append(0, budgetaccuracy[col_name_accuracy].values)\n",
    "\n",
    "                # create the column name for iterated validation loss\n",
    "                col_name_data = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' data'\n",
    "                )\n",
    "                col_name_accuracy = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' accuracy'\n",
    "                )\n",
    "\n",
    "                # get training losses for mode 1 with validation updates\n",
    "                AL_data = np.append(0, budgetaccuracy[col_name_data].values)\n",
    "                AL_accuracy = np.append(0, budgetaccuracy[col_name_accuracy].values)\n",
    "\n",
    "                if len(PRED_TYPE_LIST) == 1:\n",
    "                    plot_ax = ax[delta]\n",
    "                else:\n",
    "                    plot_ax = ax[index_pred, delta]\n",
    "                    \n",
    "                    \n",
    "                # plot iterated training losses\n",
    "                plot_ax.plot(\n",
    "                    AL_accuracy,\n",
    "                    color='b'\n",
    "                )\n",
    "\n",
    "                for x,y in enumerate(AL_accuracy):\n",
    "\n",
    "                    # plot annotations only on every second step\n",
    "                    if (x+1)%2 == 0:\n",
    "                        plot_ax.annotate(\n",
    "                            str(AL_data[x])+'%',\n",
    "                            (x, y+5)\n",
    "                        )\n",
    "\n",
    "                # plot PL accuracy.\n",
    "                # Note: Moved plotting down after plotting AL, in order to have legends aligned with height of plots\n",
    "                plot_ax.plot(\n",
    "                    PL_accuracy, \n",
    "                    color='r',\n",
    "                )\n",
    "\n",
    "                plot_ax.set_ylim(\n",
    "                    top=100\n",
    "                )\n",
    "\n",
    "                for x,y in enumerate(PL_accuracy):\n",
    "                    # plot annotations only on every second step\n",
    "                    if (x+1)%2 == 0:\n",
    "                        plot_ax.annotate(\n",
    "                            str(PL_data[x])+'%',\n",
    "                            (x, y-5)\n",
    "                        )\n",
    "\n",
    "                \n",
    "                # set subplot titles\n",
    "                plot_ax.set_title(fig_title_list[plot_counter])\n",
    "                plot_counter+= 1\n",
    "                \n",
    "                if len(PRED_TYPE_LIST) == 1:\n",
    "                    # set y-axis labels\n",
    "                    ax[0].set_ylabel(\n",
    "                        '{} \\n prediction accuracy'.format(pred_type), \n",
    "                        fontsize=FONTSIZE\n",
    "                    )\n",
    "\n",
    "                    # set x-axis\n",
    "                    ax[delta].set_xlabel(\n",
    "                        'data selection \\n iteration', \n",
    "                        fontsize=FONTSIZE\n",
    "                    )\n",
    "                else:\n",
    "                    # set y-axis labels\n",
    "                    ax[index_pred, 0].set_ylabel(\n",
    "                        '{} \\n prediction accuracy'.format(pred_type), \n",
    "                        fontsize=FONTSIZE\n",
    "                    )\n",
    "\n",
    "                    # set x-axis\n",
    "                    ax[len(PRED_TYPE_LIST)-1, delta].set_xlabel(\n",
    "                        'data selection \\n iteration', \n",
    "                        fontsize=FONTSIZE\n",
    "                    )\n",
    "\n",
    "\n",
    "        # set column titles\n",
    "        cols = [\n",
    "            'δ=0 \\n a.', \n",
    "            'δ=1 \\n b.'\n",
    "        ]\n",
    "        if len(PRED_TYPE_LIST) == 1:\n",
    "            for axes, col in zip(ax, cols):\n",
    "                axes.set_title(col)\n",
    "        else:\n",
    "            for axes, col in zip(ax[0], cols):\n",
    "                axes.set_title(col)\n",
    "\n",
    "        # create saving paths \n",
    "        saving_path = (\n",
    "            path_to_saving_budgetvsaccuracy \n",
    "            + AL_variable\n",
    "            + ' '\n",
    "            + AL_variant\n",
    "            + '.pdf'\n",
    "        )\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], color='b', label='Active learning', markersize=FONTSIZE),\n",
    "                           Line2D([0], [0], color='r', label='Passive learning', markersize=FONTSIZE),\n",
    "                           Line2D([0], [0], color='w', label='% = budget usage', markersize=FONTSIZE)]\n",
    "\n",
    "        # set layout tight\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.legend(\n",
    "            handles=legend_elements, \n",
    "            loc='upper center', \n",
    "            bbox_to_anchor=(0.9,1.08 - 0.02 *len(PRED_TYPE_LIST))\n",
    "        )\n",
    "\n",
    "        # save figures\n",
    "        fig.savefig(saving_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exemplar predictions\n",
    "\n",
    "For each experiment, we have saved a sample of 1,000 randomly chosen data points that were not queried by our passive learning or active learning algorithm when these terminated. Here, we loadfive exemplar points for each of our conducted experiments from these at random and compare the prediction of each of our three models. The first column represents the performance of the initial model prior to being further trained on any data from the candidate data pool. The second column represents the performance of our passively trained benchmark model. The third column represents the performance of our actively trained prediction model.\n",
    "\n",
    "What we ideally want to observe visually is that the prediction performance of our actively trained models is approximately as good as the performance of our passively trained models, as we are able to use fewer data points and sensors with our active learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "# choose how many random datapoints to predict and plot\n",
    "N_DATAPOINTS = 5\n",
    "\n",
    "# number of columns to plot data points. Keep this 3\n",
    "n_cols = 3\n",
    "\n",
    "# choose a different font size for these figures\n",
    "FONTSIZE = 14\n",
    "\n",
    "# set the fontsize\n",
    "mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "  \n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12]) \n",
    "\n",
    "        # provide paths to initial and PL models and samples\n",
    "        path_to_initial_model = (\n",
    "            path_to_models \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + initial_model_filename\n",
    "        )\n",
    "        path_to_PL_model = (\n",
    "            path_to_models \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + PL_model_filename\n",
    "        )\n",
    "        path_to_PL_data = (\n",
    "            path_to_samples \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type\n",
    "            + '/' \n",
    "            + 'PL_'\n",
    "        )\n",
    "        \n",
    "        # import models and samples for PL\n",
    "        initial_model =  tf.keras.models.load_model(\n",
    "            path_to_initial_model, \n",
    "            compile=False\n",
    "        )\n",
    "        PL_model = tf.keras.models.load_model(\n",
    "            path_to_PL_model, \n",
    "            compile=False\n",
    "        )\n",
    "        \n",
    "        path_to_file = path_to_PL_data + 'X_t.npy' \n",
    "        X_t = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_s.npy' \n",
    "        X_s = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_s1.npy' \n",
    "        X_s1 = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_st.npy' \n",
    "        X_st = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'Y.npy' \n",
    "        Y_pl = np.load(path_to_file)\n",
    "        \n",
    "        # make predictions\n",
    "        initial_predictions = initial_model.predict(\n",
    "            [X_t, X_s1, X_st]\n",
    "        )\n",
    "        PL_predictions = PL_model.predict(\n",
    "            [X_t, X_s1, X_st]\n",
    "        )\n",
    "\n",
    "        # iterate over all AL variables\n",
    "        for index_var, AL_variable in enumerate(AL_VARIABLES):\n",
    "            \n",
    "            # iterate over all AL variants\n",
    "            for index_method, AL_variant in enumerate(AL_VARIANTS):\n",
    "                \n",
    "                # create figure\n",
    "                fig, ax = plt.subplots(\n",
    "                    N_DATAPOINTS, \n",
    "                    n_cols, \n",
    "                    sharex=True , \n",
    "                    figsize=(16, N_DATAPOINTS * 4)\n",
    "                )\n",
    "\n",
    "                AL_model_filename = '{} {}.h5'.format(\n",
    "                    AL_variable, \n",
    "                    AL_variant\n",
    "                )\n",
    "                AL_sample_name = '{} {} '.format(\n",
    "                    AL_variable, \n",
    "                    AL_variant\n",
    "                )\n",
    "                \n",
    "                # provide paths to initial and PL models and samples\n",
    "                path_to_AL_model = (\n",
    "                    path_to_models \n",
    "                    + parameter \n",
    "                    + '/' \n",
    "                    + pred_type \n",
    "                    + '/' \n",
    "                    + AL_model_filename\n",
    "                )\n",
    "                path_to_AL_data = (\n",
    "                    path_to_samples \n",
    "                    + parameter \n",
    "                    + '/' \n",
    "                    + pred_type \n",
    "                    + '/' \n",
    "                    + AL_sample_name\n",
    "                )\n",
    "                \n",
    "                \n",
    "                # import models and samples for AL\n",
    "                AL_model =  tf.keras.models.load_model(\n",
    "                    path_to_AL_model, \n",
    "                    compile=False\n",
    "                )\n",
    "        \n",
    "                path_to_file = path_to_AL_data + 'X_t.npy' \n",
    "                X_t = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_s.npy' \n",
    "                X_s = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_s1.npy' \n",
    "                X_s1 = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_st.npy' \n",
    "                X_st = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'Y.npy' \n",
    "                Y_al = np.load(path_to_file)\n",
    "                \n",
    "                # make predictions\n",
    "                AL_predictions = AL_model.predict(\n",
    "                    [X_t, X_s1, X_st]\n",
    "                )\n",
    "                \n",
    "                # plot predictions for randomly chosen points\n",
    "                rnd_index_array_initial = np.random.choice(\n",
    "                    np.arange(len(Y_pl)),\n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "                rnd_index_array_PL = np.random.choice(\n",
    "                    np.arange(len(Y_pl)),\n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "                rnd_index_array_AL = np.random.choice(\n",
    "                    np.arange(len(Y_al)), \n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "\n",
    "                title_counter = 0\n",
    "                \n",
    "                # iterate over each row of figure\n",
    "                for row in range(N_DATAPOINTS):\n",
    "                    \n",
    "                    plot1 = ax[row, 0].plot(\n",
    "                        initial_predictions[\n",
    "                            rnd_index_array_initial[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 1].plot(\n",
    "                        PL_predictions[\n",
    "                            rnd_index_array_PL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 2].plot(\n",
    "                        AL_predictions[\n",
    "                            rnd_index_array_AL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    plot2 = ax[row, 0].plot(\n",
    "                        Y_pl[\n",
    "                            rnd_index_array_initial[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 1].plot(\n",
    "                        Y_pl[\n",
    "                            rnd_index_array_PL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 2].plot(\n",
    "                        Y_al[\n",
    "                            rnd_index_array_AL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    # set title\n",
    "                    for col in range(n_cols):\n",
    "                        ax[row, col].set_title(fig_title_list[title_counter])\n",
    "                        title_counter +=1\n",
    "                \n",
    "                # add a figure legend\n",
    "                fig.legend(\n",
    "                    [plot1, plot2], \n",
    "                    labels=['true load profile', 'predicted load profile'], \n",
    "                    loc='upper center', \n",
    "                    bbox_to_anchor=(0.8, 0.95)\n",
    "                )\n",
    "\n",
    "                colname_list = [\n",
    "                    'Initial model \\n a.', \n",
    "                    'Passive learning \\n b.', \n",
    "                    'Active learning \\n c.'\n",
    "                ]\n",
    "\n",
    "                # set col names\n",
    "                for axes, colname in zip(ax[0], colname_list):\n",
    "                    axes.set_title(colname)\n",
    "\n",
    "                # set one y- and x-axis for all sub plots\n",
    "                fig.add_subplot(111, frame_on=False)\n",
    "                plt.tick_params(\n",
    "                    labelcolor=\"none\", \n",
    "                    bottom=False, \n",
    "                    left=False\n",
    "                )\n",
    "                plt.xlabel(\n",
    "                    'time [15-min]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                plt.ylabel(\n",
    "                    'building electric consumption [kW]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                \n",
    "                filename = '{} {} {} delta{} valup{}.pdf'.format(\n",
    "                    pred_type, \n",
    "                    AL_variable, \n",
    "                    AL_variant, \n",
    "                    delta, \n",
    "                    valup\n",
    "                )\n",
    "\n",
    "                saving_path = (\n",
    "                    path_to_exemplar_predictions \n",
    "                    + filename\n",
    "                )\n",
    "\n",
    "                fig.savefig(saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Manuscript: Data selection maps\n",
    "\n",
    "Our findings can have important implications for the energy transition to a carbon free power systems and therefore for mitigating climate change. The ADL method we propose can be used by distribution and transmission system operators for electricity to make overall more accurate predictions of electric load using budgets for installing smart meters and streaming their data more effectively. This figure is supposed to visualize how ADL can show us where to place sensors and when to collect their data as we proceed in time (a. - f.). We start with choosing a set of locations to place sensors uniformly at random (a.). Then, we collect training data for making spatio-temporal predictions and learn where to best place a relatively large set of new sensors next (b.). Next, we iteratively place fewer sensors to make better predictions in the most informative sequence (c. - f.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "\n",
    "# define some hyper for plots\n",
    "n_rows = 3\n",
    "n_cols = 2\n",
    "n_iter_plot = n_rows * n_cols - 1\n",
    "n_meshes_surface = 10\n",
    "FONTSIZE = 22\n",
    "\n",
    "# import building meta data\n",
    "path_to_building_meta = '../data/private/' + profile_set + '/meta/meta buildings.csv'\n",
    "building_meta = pd.read_csv(path_to_building_meta)\n",
    "\n",
    "def create_bottom_plot(df_initial_sensors):\n",
    "\n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df_initial_sensors['building lat'].min()\n",
    "    max_lat = df_initial_sensors['building lat'].max() \n",
    "    min_long = df_initial_sensors['building long'].min()\n",
    "    max_long = df_initial_sensors['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    map_height = 0\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df_initial_sensors['building long'], \n",
    "        df_initial_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    ) \n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(map_height)\n",
    "    \n",
    "def create_plot(time_data, df, df_new_sensors):\n",
    "    \n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df['building lat'].min()\n",
    "    max_lat = df['building lat'].max() \n",
    "    min_long = df['building long'].min()\n",
    "    max_long = df['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    # update max time point\n",
    "    min_time_point, max_time_point = min(time_data), max(time_data)\n",
    "    map_height = max_time_point/3 * (1 + 3* iteration/n_iter_plot)\n",
    "    shifting_time = max_time_point - map_height\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df['building long'], \n",
    "        df['building lat'], \n",
    "        time_data - shifting_time, \n",
    "        c=time_data, alpha=0.7\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df_new_sensors['building long'], \n",
    "        df_new_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(min_time_point - shifting_time, max_time_point)\n",
    "    \n",
    "\n",
    "def customize_plot(iteration):\n",
    "    \n",
    "    # set angle\n",
    "    ax.view_init(30, 110)\n",
    "    \n",
    "    # Get rid of the panes\n",
    "    ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "\n",
    "    # Get rid of the ticks\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # Add the labels\n",
    "    ax.set_xlabel('long', fontsize=FONTSIZE)\n",
    "    ax.set_ylabel('lat', fontsize=FONTSIZE)\n",
    "    ax.set_zlabel('time', fontsize=FONTSIZE)\n",
    "\n",
    "    # shift time (z) axis\n",
    "    tmp_planes = ax.zaxis._PLANES \n",
    "    ax.zaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    # shift lat (y) axis\n",
    "    ax.yaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # set subplot titles\n",
    "    ax.set_title(\n",
    "        fig_title_list[plot_counter-1].format(iteration+1), \n",
    "        fontsize=FONTSIZE + 4\n",
    "    )\n",
    "\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        spacetime_result = spacetime_selection_list[result_index_counter]\n",
    "\n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        for AL_variable in AL_VARIABLES:\n",
    "            \n",
    "            for AL_variant in AL_VARIANTS:\n",
    "        \n",
    "                # create figure\n",
    "                fig = plt.figure(figsize=(16, n_rows * 8))\n",
    "\n",
    "                # set the fontsize for figures\n",
    "                mpl.rcParams.update({'font.size': 16}) #FONTSIZE\n",
    "\n",
    "                colname_initial_sensors = '{} - initial sensors'.format(pred_type)\n",
    "                intial_sensors = spacetime_result[colname_initial_sensors]\n",
    "                df_initial_sensors = pd.DataFrame({'building ID':intial_sensors})\n",
    "                df_initial_sensors = df_initial_sensors.merge(building_meta, on='building ID', how='left')\n",
    "                \n",
    "                plot_counter= 1\n",
    "                ax = fig.add_subplot(n_rows, n_cols, plot_counter, projection='3d')\n",
    "                create_bottom_plot(df_initial_sensors)\n",
    "                customize_plot(iteration=0)\n",
    "                plot_counter += 1\n",
    "                old_senors_AL_set = set(intial_sensors)\n",
    "                old_senors_PL_set = set(intial_sensors)\n",
    "                for iteration in range(n_iter_plot):\n",
    "\n",
    "                    # create column names\n",
    "                    colname_AL_times = '{} {} {} - iter {} time'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    colname_AL_spaces = '{} {} {} - iter {} space'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    \n",
    "                    ### Plot AL results on left column ###\n",
    "                    \n",
    "                    # get data\n",
    "                    space_data_AL = spacetime_result[colname_AL_spaces]\n",
    "                    time_data_AL = spacetime_result[colname_AL_times]\n",
    "\n",
    "                    # get new sensors and set old sensors\n",
    "                    new_sensors_AL_set = set(space_data_AL).union(old_senors_AL_set)\n",
    "                    new_sensors_AL_list = list(new_sensors_AL_set - old_senors_AL_set)\n",
    "                    old_senors_AL_set = new_sensors_AL_set\n",
    "                    \n",
    "                    # assign lat and long to building IDs\n",
    "                    df_AL = pd.DataFrame({'building ID':space_data_AL})\n",
    "                    df_AL = df_AL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    df_new_sensors_AL = pd.DataFrame({'building ID':new_sensors_AL_list})\n",
    "                    df_new_sensors_AL = df_new_sensors_AL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    # AL temporal scatter plot\n",
    "                    ax = fig.add_subplot(n_rows, n_cols, plot_counter, projection='3d')\n",
    "                    create_plot(time_data_AL, df_AL, df_new_sensors_AL)\n",
    "                    customize_plot(iteration)\n",
    "                    plot_counter += 1\n",
    "\n",
    "                # create saving paths \n",
    "                saving_path = (\n",
    "                    path_to_ADL_selection \n",
    "                    + pred_type\n",
    "                    + ' '\n",
    "                    + parameter\n",
    "                    + ' '\n",
    "                    + AL_variable\n",
    "                    + ' '\n",
    "                    + AL_variant\n",
    "                    + '.pdf'\n",
    "                )\n",
    "\n",
    "                # create a legend\n",
    "                legend_elements = [\n",
    "                    Line2D([0], [0], marker='o', color='w', markerfacecolor='b', markersize=10, label='query in space-time'),\n",
    "                    Line2D([0], [0], marker='X', color='w', markerfacecolor='r', markersize=15, label='new sensor in space')\n",
    "                ]\n",
    "\n",
    "                # set layout tight\n",
    "                fig.tight_layout()\n",
    "\n",
    "                fig.legend(handles=legend_elements, loc='upper right', bbox_to_anchor=(0.6, 1), fontsize=FONTSIZE)\n",
    "\n",
    "                # save figures\n",
    "                fig.savefig(saving_path, bbox_inches=\"tight\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
