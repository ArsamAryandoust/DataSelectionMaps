{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Result figures for *Enhanced spatio-temporal electric load forecasts with less data using active deep learning*\n",
    "\n",
    "---\n",
    "\n",
    "## Overview\n",
    "1. Import and test results\n",
    "2. Numeric results\n",
    "3. Space and time selection\n",
    "4. Budget vs. accuracy\n",
    "5. Training and validation losses against unqueried candidates\n",
    "6. Validation losses against all candidates\n",
    "7. Query sequence importance\n",
    "8. Exemplar predictions\n",
    "\n",
    "In this notebook session, we summarize and visualize the experimental results of our manuscript. We start with selecting the respective set of experimental results that we want to compare to each other, and import a number of packages that we use throughout this notebook session. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Set some parameters ###\n",
    "\n",
    "# choose which results dataset you want to process\n",
    "profile_set = 'profiles_400'\n",
    "\n",
    "# prediction types to consider\n",
    "PRED_TYPE_LIST = [\n",
    "    'spatial',\n",
    "    #'temporal',\n",
    "    #'spatio-temporal'\n",
    "]\n",
    "\n",
    "# parameter constellations to consider\n",
    "PARAMETER_LIST = [\n",
    "    'delta0_valup0', \n",
    "    'delta0_valup1', \n",
    "    #'delta1_valup0', \n",
    "    #'delta1_valup1'\n",
    "]\n",
    "\n",
    "\n",
    "# choose which AL variables to plot. Choose from 'X_t', 'X_s1', 'X_st', 'X_joint', 'X_(t,s)', 'Y_(t,s)'\n",
    "AL_VARIABLES = [\n",
    "#    'X_t', \n",
    "#    'X_s1', \n",
    "    'X_st', \n",
    "    'X_(t,s)', \n",
    "    'Y_hat_(t,s)', \n",
    "    'Y_(t,s)'\n",
    "]\n",
    "\n",
    "\n",
    "# choose which AL variables to plot. Choose from 'X_t', 'X_s1', 'X_st', 'X_joint', 'X_(t,s)', 'Y_(t,s)'\n",
    "AL_VARIANTS = [\n",
    "    'rnd d_c', \n",
    "    'max d_c', \n",
    "    'min d_c', \n",
    "    'avg d_c'\n",
    "]\n",
    "\n",
    "\n",
    "# create figure sub title list\n",
    "fig_title_list = [\n",
    "    'a.', 'b.', 'c.', 'd.', 'e.', 'f.', 'g.', 'h.',\n",
    "    'i.', 'j.', 'k.', 'l.', 'm.', 'n.', 'o.', 'p.',\n",
    "    'q.', 'r.', 's.', 't.', 'u.', 'v.', 'w.', 'x.'\n",
    "]\n",
    "\n",
    "# set width\n",
    "WIDTH_FACTOR = 8\n",
    "\n",
    "# set universal fontsize\n",
    "FONTSIZE = 20\n",
    "\n",
    "### Import packages ###\n",
    "\n",
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib.lines import Line2D\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import math\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "\n",
    "\n",
    "### Provide import paths and file names ###\n",
    "\n",
    "# path to results folder\n",
    "path_to_results = '../results/' + profile_set + '/'\n",
    "\n",
    "# path to initially trained encoders and prediction model\n",
    "path_to_encoders = path_to_results + 'encoder weights/'\n",
    "\n",
    "# path to numeric result values\n",
    "path_to_values = path_to_results + 'values/'\n",
    "\n",
    "# path to unseen test samples\n",
    "path_to_samples = path_to_results + 'samples/'\n",
    "\n",
    "# path to models \n",
    "path_to_models = path_to_results + 'models/'\n",
    "\n",
    "# individual file names\n",
    "hyper_filename = 'hyper.csv'\n",
    "results_filename = 'results.csv'\n",
    "seqimportance_filename = 'sequence_importance.csv'\n",
    "spacetime_selection_filename = 'spacetime_selection.csv'\n",
    "budgetaccuracy_filename = 'budget_vs_accuracy.csv'\n",
    "\n",
    "initial_model_filename = 'initial.h5'\n",
    "PL_model_filename = 'PL.h5'\n",
    "\n",
    "### Provide export paths and file names ###\n",
    "\n",
    "# path to saving result figures\n",
    "path_to_saving_figures = path_to_results + 'figures/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_figures):\n",
    "    os.mkdir(path_to_saving_figures)\n",
    "\n",
    "# path to subfolder for saving spacetime point selection\n",
    "path_to_saving_spacetime = path_to_saving_figures + 'space-time selection/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_spacetime):\n",
    "    os.mkdir(path_to_saving_spacetime)\n",
    "    \n",
    "# path to subfolder for saving budgetvsaccuracy\n",
    "path_to_saving_budgetvsaccuracy = path_to_saving_figures + 'budget vs accuracy/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_budgetvsaccuracy):\n",
    "    os.mkdir(path_to_saving_budgetvsaccuracy)\n",
    "    \n",
    "# path to subfolder for saving lossesvsunqueried\n",
    "path_to_saving_lossesvsunqueried = path_to_saving_figures + 'losses vs unqueried candidates/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_lossesvsunqueried):\n",
    "    os.mkdir(path_to_saving_lossesvsunqueried)\n",
    "    \n",
    "# path to subfolder for saving lossesvsall\n",
    "path_to_saving_lossesvsall = path_to_saving_figures + 'losses vs all candidates/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_lossesvsall):\n",
    "    os.mkdir(path_to_saving_lossesvsall)\n",
    "    \n",
    "# path to subfolder for saving seqimportance\n",
    "path_to_saving_seqimportance = path_to_saving_figures + 'sequence importance/'\n",
    "\n",
    "if not os.path.exists(path_to_saving_seqimportance):\n",
    "    os.mkdir(path_to_saving_seqimportance)\n",
    "    \n",
    "# path to subfolder for saving exemplar predictions point selection\n",
    "path_to_exemplar_predictions = path_to_saving_figures + 'exemplar predictions/'\n",
    "\n",
    "if not os.path.exists(path_to_exemplar_predictions):\n",
    "    os.mkdir(path_to_exemplar_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import and test results\n",
    "\n",
    "Here, we import the results and the hyper parameters that were used in each of our experiment. We check whether all imported results are calculated on the exact same hyper parameters for the hypothesis test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>private_data_access</th>\n",
       "      <th>test_sequence_importance</th>\n",
       "      <th>save_act_lrn_results</th>\n",
       "      <th>save_hyper_params</th>\n",
       "      <th>save_act_lrn_models</th>\n",
       "      <th>save_act_lrn_test_sample</th>\n",
       "      <th>pred_list_act_lrn</th>\n",
       "      <th>query_variants_act_lrn</th>\n",
       "      <th>query_variables_act_lrn</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_data</th>\n",
       "      <th>time_encoding</th>\n",
       "      <th>spatial_features</th>\n",
       "      <th>histo_bins</th>\n",
       "      <th>grey_scale</th>\n",
       "      <th>down_scale_building_images</th>\n",
       "      <th>meteo_types</th>\n",
       "      <th>history_window_meteo</th>\n",
       "      <th>normalization</th>\n",
       "      <th>standardization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>spatial</td>\n",
       "      <td>rnd d_c</td>\n",
       "      <td>X_st</td>\n",
       "      <td>...</td>\n",
       "      <td>15min</td>\n",
       "      <td>ORD</td>\n",
       "      <td>histogram</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_density</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>min d_c</td>\n",
       "      <td>X_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cloud_cover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>max d_c</td>\n",
       "      <td>Y_hat_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg d_c</td>\n",
       "      <td>Y_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radiation_surface</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radiation_toa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snow_mass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snowfall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wind_speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 private_data_access test_sequence_importance  \\\n",
       "0           0                True                     True   \n",
       "1           1                 NaN                      NaN   \n",
       "2           2                 NaN                      NaN   \n",
       "3           3                 NaN                      NaN   \n",
       "4           4                 NaN                      NaN   \n",
       "5           5                 NaN                      NaN   \n",
       "6           6                 NaN                      NaN   \n",
       "7           7                 NaN                      NaN   \n",
       "8           8                 NaN                      NaN   \n",
       "\n",
       "  save_act_lrn_results save_hyper_params save_act_lrn_models  \\\n",
       "0                 True              True                True   \n",
       "1                  NaN               NaN                 NaN   \n",
       "2                  NaN               NaN                 NaN   \n",
       "3                  NaN               NaN                 NaN   \n",
       "4                  NaN               NaN                 NaN   \n",
       "5                  NaN               NaN                 NaN   \n",
       "6                  NaN               NaN                 NaN   \n",
       "7                  NaN               NaN                 NaN   \n",
       "8                  NaN               NaN                 NaN   \n",
       "\n",
       "  save_act_lrn_test_sample pred_list_act_lrn query_variants_act_lrn  \\\n",
       "0                     True           spatial                rnd d_c   \n",
       "1                      NaN               NaN                min d_c   \n",
       "2                      NaN               NaN                max d_c   \n",
       "3                      NaN               NaN                avg d_c   \n",
       "4                      NaN               NaN                    NaN   \n",
       "5                      NaN               NaN                    NaN   \n",
       "6                      NaN               NaN                    NaN   \n",
       "7                      NaN               NaN                    NaN   \n",
       "8                      NaN               NaN                    NaN   \n",
       "\n",
       "  query_variables_act_lrn  ... timestamp_data time_encoding spatial_features  \\\n",
       "0                    X_st  ...          15min           ORD        histogram   \n",
       "1                 X_(t,s)  ...           hour           NaN              NaN   \n",
       "2             Y_hat_(t,s)  ...            day           NaN              NaN   \n",
       "3                 Y_(t,s)  ...          month           NaN              NaN   \n",
       "4                     NaN  ...            NaN           NaN              NaN   \n",
       "5                     NaN  ...            NaN           NaN              NaN   \n",
       "6                     NaN  ...            NaN           NaN              NaN   \n",
       "7                     NaN  ...            NaN           NaN              NaN   \n",
       "8                     NaN  ...            NaN           NaN              NaN   \n",
       "\n",
       "   histo_bins  grey_scale  down_scale_building_images        meteo_types  \\\n",
       "0       100.0       False                         NaN        air_density   \n",
       "1         NaN         NaN                         NaN        cloud_cover   \n",
       "2         NaN         NaN                         NaN      precipitation   \n",
       "3         NaN         NaN                         NaN  radiation_surface   \n",
       "4         NaN         NaN                         NaN      radiation_toa   \n",
       "5         NaN         NaN                         NaN          snow_mass   \n",
       "6         NaN         NaN                         NaN           snowfall   \n",
       "7         NaN         NaN                         NaN        temperature   \n",
       "8         NaN         NaN                         NaN         wind_speed   \n",
       "\n",
       "   history_window_meteo normalization standardization  \n",
       "0                  24.0          True            True  \n",
       "1                   NaN           NaN             NaN  \n",
       "2                   NaN           NaN             NaN  \n",
       "3                   NaN           NaN             NaN  \n",
       "4                   NaN           NaN             NaN  \n",
       "5                   NaN           NaN             NaN  \n",
       "6                   NaN           NaN             NaN  \n",
       "7                   NaN           NaN             NaN  \n",
       "8                   NaN           NaN             NaN  \n",
       "\n",
       "[9 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>private_data_access</th>\n",
       "      <th>test_sequence_importance</th>\n",
       "      <th>save_act_lrn_results</th>\n",
       "      <th>save_hyper_params</th>\n",
       "      <th>save_act_lrn_models</th>\n",
       "      <th>save_act_lrn_test_sample</th>\n",
       "      <th>pred_list_act_lrn</th>\n",
       "      <th>query_variants_act_lrn</th>\n",
       "      <th>query_variables_act_lrn</th>\n",
       "      <th>...</th>\n",
       "      <th>timestamp_data</th>\n",
       "      <th>time_encoding</th>\n",
       "      <th>spatial_features</th>\n",
       "      <th>histo_bins</th>\n",
       "      <th>grey_scale</th>\n",
       "      <th>down_scale_building_images</th>\n",
       "      <th>meteo_types</th>\n",
       "      <th>history_window_meteo</th>\n",
       "      <th>normalization</th>\n",
       "      <th>standardization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>spatial</td>\n",
       "      <td>rnd d_c</td>\n",
       "      <td>X_st</td>\n",
       "      <td>...</td>\n",
       "      <td>15min</td>\n",
       "      <td>ORD</td>\n",
       "      <td>histogram</td>\n",
       "      <td>100.0</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>air_density</td>\n",
       "      <td>24.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>min d_c</td>\n",
       "      <td>X_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>hour</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>cloud_cover</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>max d_c</td>\n",
       "      <td>Y_hat_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>day</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>precipitation</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>avg d_c</td>\n",
       "      <td>Y_(t,s)</td>\n",
       "      <td>...</td>\n",
       "      <td>month</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radiation_surface</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>radiation_toa</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snow_mass</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>snowfall</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>temperature</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>wind_speed</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 private_data_access test_sequence_importance  \\\n",
       "0           0                True                     True   \n",
       "1           1                 NaN                      NaN   \n",
       "2           2                 NaN                      NaN   \n",
       "3           3                 NaN                      NaN   \n",
       "4           4                 NaN                      NaN   \n",
       "5           5                 NaN                      NaN   \n",
       "6           6                 NaN                      NaN   \n",
       "7           7                 NaN                      NaN   \n",
       "8           8                 NaN                      NaN   \n",
       "\n",
       "  save_act_lrn_results save_hyper_params save_act_lrn_models  \\\n",
       "0                 True              True                True   \n",
       "1                  NaN               NaN                 NaN   \n",
       "2                  NaN               NaN                 NaN   \n",
       "3                  NaN               NaN                 NaN   \n",
       "4                  NaN               NaN                 NaN   \n",
       "5                  NaN               NaN                 NaN   \n",
       "6                  NaN               NaN                 NaN   \n",
       "7                  NaN               NaN                 NaN   \n",
       "8                  NaN               NaN                 NaN   \n",
       "\n",
       "  save_act_lrn_test_sample pred_list_act_lrn query_variants_act_lrn  \\\n",
       "0                     True           spatial                rnd d_c   \n",
       "1                      NaN               NaN                min d_c   \n",
       "2                      NaN               NaN                max d_c   \n",
       "3                      NaN               NaN                avg d_c   \n",
       "4                      NaN               NaN                    NaN   \n",
       "5                      NaN               NaN                    NaN   \n",
       "6                      NaN               NaN                    NaN   \n",
       "7                      NaN               NaN                    NaN   \n",
       "8                      NaN               NaN                    NaN   \n",
       "\n",
       "  query_variables_act_lrn  ... timestamp_data time_encoding spatial_features  \\\n",
       "0                    X_st  ...          15min           ORD        histogram   \n",
       "1                 X_(t,s)  ...           hour           NaN              NaN   \n",
       "2             Y_hat_(t,s)  ...            day           NaN              NaN   \n",
       "3                 Y_(t,s)  ...          month           NaN              NaN   \n",
       "4                     NaN  ...            NaN           NaN              NaN   \n",
       "5                     NaN  ...            NaN           NaN              NaN   \n",
       "6                     NaN  ...            NaN           NaN              NaN   \n",
       "7                     NaN  ...            NaN           NaN              NaN   \n",
       "8                     NaN  ...            NaN           NaN              NaN   \n",
       "\n",
       "   histo_bins  grey_scale  down_scale_building_images        meteo_types  \\\n",
       "0       100.0       False                         NaN        air_density   \n",
       "1         NaN         NaN                         NaN        cloud_cover   \n",
       "2         NaN         NaN                         NaN      precipitation   \n",
       "3         NaN         NaN                         NaN  radiation_surface   \n",
       "4         NaN         NaN                         NaN      radiation_toa   \n",
       "5         NaN         NaN                         NaN          snow_mass   \n",
       "6         NaN         NaN                         NaN           snowfall   \n",
       "7         NaN         NaN                         NaN        temperature   \n",
       "8         NaN         NaN                         NaN         wind_speed   \n",
       "\n",
       "   history_window_meteo normalization standardization  \n",
       "0                  24.0          True            True  \n",
       "1                   NaN           NaN             NaN  \n",
       "2                   NaN           NaN             NaN  \n",
       "3                   NaN           NaN             NaN  \n",
       "4                   NaN           NaN             NaN  \n",
       "5                   NaN           NaN             NaN  \n",
       "6                   NaN           NaN             NaN  \n",
       "7                   NaN           NaN             NaN  \n",
       "8                   NaN           NaN             NaN  \n",
       "\n",
       "[9 rows x 63 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "### Import the results ###\n",
    "\n",
    "hyper_list = []\n",
    "results_list = []\n",
    "seqimportance_list = []\n",
    "spacetime_selection_list = []\n",
    "budgetaccuracy_list = []\n",
    "\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "        \n",
    "        path_to_hyper_parameters = (\n",
    "            path_to_values \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + hyper_filename\n",
    "        )\n",
    "        path_to_results = (\n",
    "            path_to_values \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + results_filename\n",
    "        )\n",
    "        path_to_seqimportance = (\n",
    "            path_to_values \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + seqimportance_filename\n",
    "        )\n",
    "        path_to_spacetime_selection = (\n",
    "            path_to_values \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + spacetime_selection_filename\n",
    "        )\n",
    "        path_to_budgetaccuracy = (\n",
    "            path_to_values \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + budgetaccuracy_filename\n",
    "        )\n",
    "        \n",
    "        hyper_list.append(\n",
    "            pd.read_csv(\n",
    "                path_to_hyper_parameters\n",
    "            )\n",
    "        )\n",
    "        results_list.append(\n",
    "            pd.read_csv(\n",
    "                path_to_results\n",
    "            )\n",
    "        )\n",
    "        seqimportance_list.append(\n",
    "            pd.read_csv(\n",
    "                path_to_seqimportance\n",
    "            )\n",
    "        )\n",
    "        spacetime_selection_list.append(\n",
    "            pd.read_csv(\n",
    "                path_to_spacetime_selection\n",
    "            )\n",
    "        )\n",
    "        budgetaccuracy_list.append(\n",
    "            pd.read_csv(\n",
    "                path_to_budgetaccuracy\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        \n",
    "### Test correctness of results ###\n",
    "\n",
    "index_counter = 0\n",
    "\n",
    "for pred_type in PRED_TYPE_LIST:\n",
    "\n",
    "    for parameter in PARAMETER_LIST:\n",
    "        \n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12])\n",
    "        \n",
    "        df_hyper = hyper_list[index_counter]\n",
    "        \n",
    "        if (df_hyper['red_cand_data_act_lrn'][0] != delta \n",
    "            or df_hyper['upd_val_data_act_lrn'][0] != valup):\n",
    "            \n",
    "            print(\n",
    "                'Caution. Wrong assignment of results for', \n",
    "                parameter, \n",
    "                'and', \n",
    "                pred_type\n",
    "            )\n",
    "\n",
    "        if index_counter > 0:\n",
    "            \n",
    "            if not df_hyper.drop(\n",
    "                [\n",
    "                    'pred_list_act_lrn', \n",
    "                    'upd_val_data_act_lrn', \n",
    "                    'red_cand_data_act_lrn'\n",
    "                ], \n",
    "                axis=1\n",
    "            ).equals(\n",
    "                previous_df.drop(\n",
    "                    [\n",
    "                        'pred_list_act_lrn', \n",
    "                        'upd_val_data_act_lrn', \n",
    "                        'red_cand_data_act_lrn'\n",
    "                    ], \n",
    "                    axis=1\n",
    "                )\n",
    "            ):\n",
    "                \n",
    "                print(\n",
    "                    'Caution. Results were not calculated on same hyper parameters for', \n",
    "                    parameter, \n",
    "                    'and', \n",
    "                    pred_type\n",
    "                )\n",
    "            \n",
    "        previous_df = df_hyper\n",
    "        index_counter += 1\n",
    "        \n",
    "        display(df_hyper)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Numeric results\n",
    "\n",
    "In this section, we conclude the percentage of the data budget that is used, the percentage of novel senors in the queried candidate data point that is selected and the testing losses for each of our conducted experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta0_valup0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>budget_usage</th>\n",
       "      <th>sensor_usage</th>\n",
       "      <th>RF_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spatial None PL train</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.271458</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial None PL val</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.271458</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st rnd d_c train</th>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.245396</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st rnd d_c val</th>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.245396</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st min d_c train</th>\n",
       "      <td>26</td>\n",
       "      <td>96</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.268249</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st min d_c val</th>\n",
       "      <td>26</td>\n",
       "      <td>96</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.268249</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st max d_c train</th>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.277693</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st max d_c val</th>\n",
       "      <td>18</td>\n",
       "      <td>50</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.277693</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st avg d_c train</th>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.316870</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st avg d_c val</th>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.316870</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) rnd d_c train</th>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.124772</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) rnd d_c val</th>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.124772</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) min d_c train</th>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) min d_c val</th>\n",
       "      <td>76</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.136800</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) max d_c train</th>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.190973</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) max d_c val</th>\n",
       "      <td>55</td>\n",
       "      <td>92</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.190973</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) avg d_c train</th>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.138487</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) avg d_c val</th>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.138487</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) rnd d_c train</th>\n",
       "      <td>48</td>\n",
       "      <td>96</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.102870</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) rnd d_c val</th>\n",
       "      <td>48</td>\n",
       "      <td>96</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.102870</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) min d_c train</th>\n",
       "      <td>51</td>\n",
       "      <td>95</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) min d_c val</th>\n",
       "      <td>51</td>\n",
       "      <td>95</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.103159</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) max d_c train</th>\n",
       "      <td>38</td>\n",
       "      <td>82</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) max d_c val</th>\n",
       "      <td>38</td>\n",
       "      <td>82</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.125603</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) avg d_c train</th>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) avg d_c val</th>\n",
       "      <td>42</td>\n",
       "      <td>90</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.091268</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) rnd d_c train</th>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) rnd d_c val</th>\n",
       "      <td>44</td>\n",
       "      <td>92</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.126984</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) min d_c train</th>\n",
       "      <td>26</td>\n",
       "      <td>68</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.248216</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) min d_c val</th>\n",
       "      <td>26</td>\n",
       "      <td>68</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.248216</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) max d_c train</th>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.274506</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) max d_c val</th>\n",
       "      <td>22</td>\n",
       "      <td>59</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.274506</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) avg d_c train</th>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.265255</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) avg d_c val</th>\n",
       "      <td>25</td>\n",
       "      <td>69</td>\n",
       "      <td>0.419067</td>\n",
       "      <td>0.265255</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0                         budget_usage  sensor_usage   RF_loss  \\\n",
       "spatial None PL train                        80           100  0.419067   \n",
       "spatial None PL val                          80           100  0.419067   \n",
       "spatial X_st rnd d_c train                   71           100  0.419067   \n",
       "spatial X_st rnd d_c val                     71           100  0.419067   \n",
       "spatial X_st min d_c train                   26            96  0.419067   \n",
       "spatial X_st min d_c val                     26            96  0.419067   \n",
       "spatial X_st max d_c train                   18            50  0.419067   \n",
       "spatial X_st max d_c val                     18            50  0.419067   \n",
       "spatial X_st avg d_c train                   18            49  0.419067   \n",
       "spatial X_st avg d_c val                     18            49  0.419067   \n",
       "spatial X_(t,s) rnd d_c train                76           100  0.419067   \n",
       "spatial X_(t,s) rnd d_c val                  76           100  0.419067   \n",
       "spatial X_(t,s) min d_c train                76           100  0.419067   \n",
       "spatial X_(t,s) min d_c val                  76           100  0.419067   \n",
       "spatial X_(t,s) max d_c train                55            92  0.419067   \n",
       "spatial X_(t,s) max d_c val                  55            92  0.419067   \n",
       "spatial X_(t,s) avg d_c train                62           100  0.419067   \n",
       "spatial X_(t,s) avg d_c val                  62           100  0.419067   \n",
       "spatial Y_hat_(t,s) rnd d_c train            48            96  0.419067   \n",
       "spatial Y_hat_(t,s) rnd d_c val              48            96  0.419067   \n",
       "spatial Y_hat_(t,s) min d_c train            51            95  0.419067   \n",
       "spatial Y_hat_(t,s) min d_c val              51            95  0.419067   \n",
       "spatial Y_hat_(t,s) max d_c train            38            82  0.419067   \n",
       "spatial Y_hat_(t,s) max d_c val              38            82  0.419067   \n",
       "spatial Y_hat_(t,s) avg d_c train            42            90  0.419067   \n",
       "spatial Y_hat_(t,s) avg d_c val              42            90  0.419067   \n",
       "spatial Y_(t,s) rnd d_c train                44            92  0.419067   \n",
       "spatial Y_(t,s) rnd d_c val                  44            92  0.419067   \n",
       "spatial Y_(t,s) min d_c train                26            68  0.419067   \n",
       "spatial Y_(t,s) min d_c val                  26            68  0.419067   \n",
       "spatial Y_(t,s) max d_c train                22            59  0.419067   \n",
       "spatial Y_(t,s) max d_c val                  22            59  0.419067   \n",
       "spatial Y_(t,s) avg d_c train                25            69  0.419067   \n",
       "spatial Y_(t,s) avg d_c val                  25            69  0.419067   \n",
       "\n",
       "Unnamed: 0                         test_loss  accuracy  \n",
       "spatial None PL train               0.271458        35  \n",
       "spatial None PL val                 0.271458        35  \n",
       "spatial X_st rnd d_c train          0.245396        41  \n",
       "spatial X_st rnd d_c val            0.245396        41  \n",
       "spatial X_st min d_c train          0.268249        36  \n",
       "spatial X_st min d_c val            0.268249        36  \n",
       "spatial X_st max d_c train          0.277693        34  \n",
       "spatial X_st max d_c val            0.277693        34  \n",
       "spatial X_st avg d_c train          0.316870        24  \n",
       "spatial X_st avg d_c val            0.316870        24  \n",
       "spatial X_(t,s) rnd d_c train       0.124772        70  \n",
       "spatial X_(t,s) rnd d_c val         0.124772        70  \n",
       "spatial X_(t,s) min d_c train       0.136800        67  \n",
       "spatial X_(t,s) min d_c val         0.136800        67  \n",
       "spatial X_(t,s) max d_c train       0.190973        54  \n",
       "spatial X_(t,s) max d_c val         0.190973        54  \n",
       "spatial X_(t,s) avg d_c train       0.138487        67  \n",
       "spatial X_(t,s) avg d_c val         0.138487        67  \n",
       "spatial Y_hat_(t,s) rnd d_c train   0.102870        75  \n",
       "spatial Y_hat_(t,s) rnd d_c val     0.102870        75  \n",
       "spatial Y_hat_(t,s) min d_c train   0.103159        75  \n",
       "spatial Y_hat_(t,s) min d_c val     0.103159        75  \n",
       "spatial Y_hat_(t,s) max d_c train   0.125603        70  \n",
       "spatial Y_hat_(t,s) max d_c val     0.125603        70  \n",
       "spatial Y_hat_(t,s) avg d_c train   0.091268        78  \n",
       "spatial Y_hat_(t,s) avg d_c val     0.091268        78  \n",
       "spatial Y_(t,s) rnd d_c train       0.126984        70  \n",
       "spatial Y_(t,s) rnd d_c val         0.126984        70  \n",
       "spatial Y_(t,s) min d_c train       0.248216        41  \n",
       "spatial Y_(t,s) min d_c val         0.248216        41  \n",
       "spatial Y_(t,s) max d_c train       0.274506        34  \n",
       "spatial Y_(t,s) max d_c val         0.274506        34  \n",
       "spatial Y_(t,s) avg d_c train       0.265255        37  \n",
       "spatial Y_(t,s) avg d_c val         0.265255        37  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "delta0_valup1\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>budget_usage</th>\n",
       "      <th>sensor_usage</th>\n",
       "      <th>RF_loss</th>\n",
       "      <th>test_loss</th>\n",
       "      <th>accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>spatial None PL train</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.488721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial None PL val</th>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.488721</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st rnd d_c train</th>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.229853</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st rnd d_c val</th>\n",
       "      <td>71</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.229853</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st min d_c train</th>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.344245</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st min d_c val</th>\n",
       "      <td>24</td>\n",
       "      <td>98</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.344245</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st max d_c train</th>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.344956</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st max d_c val</th>\n",
       "      <td>17</td>\n",
       "      <td>48</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.344956</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st avg d_c train</th>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.336658</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_st avg d_c val</th>\n",
       "      <td>18</td>\n",
       "      <td>47</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.336658</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) rnd d_c train</th>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.119214</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) rnd d_c val</th>\n",
       "      <td>77</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.119214</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) min d_c train</th>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.152110</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) min d_c val</th>\n",
       "      <td>74</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.152110</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) max d_c train</th>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) max d_c val</th>\n",
       "      <td>51</td>\n",
       "      <td>83</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.160277</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) avg d_c train</th>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.126024</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial X_(t,s) avg d_c val</th>\n",
       "      <td>62</td>\n",
       "      <td>100</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.126024</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) rnd d_c train</th>\n",
       "      <td>49</td>\n",
       "      <td>98</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.076669</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) rnd d_c val</th>\n",
       "      <td>49</td>\n",
       "      <td>98</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.076669</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) min d_c train</th>\n",
       "      <td>49</td>\n",
       "      <td>95</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) min d_c val</th>\n",
       "      <td>49</td>\n",
       "      <td>95</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.090226</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) max d_c train</th>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) max d_c val</th>\n",
       "      <td>38</td>\n",
       "      <td>80</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.115200</td>\n",
       "      <td>73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) avg d_c train</th>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.085773</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_hat_(t,s) avg d_c val</th>\n",
       "      <td>40</td>\n",
       "      <td>84</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.085773</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) rnd d_c train</th>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.144567</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) rnd d_c val</th>\n",
       "      <td>42</td>\n",
       "      <td>92</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.144567</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) min d_c train</th>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.274123</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) min d_c val</th>\n",
       "      <td>27</td>\n",
       "      <td>63</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.274123</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) max d_c train</th>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.304108</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) max d_c val</th>\n",
       "      <td>23</td>\n",
       "      <td>57</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.304108</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) avg d_c train</th>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>spatial Y_(t,s) avg d_c val</th>\n",
       "      <td>25</td>\n",
       "      <td>64</td>\n",
       "      <td>0.422028</td>\n",
       "      <td>0.285902</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Unnamed: 0                         budget_usage  sensor_usage   RF_loss  \\\n",
       "spatial None PL train                        80           100  0.422028   \n",
       "spatial None PL val                          80           100  0.422028   \n",
       "spatial X_st rnd d_c train                   71           100  0.422028   \n",
       "spatial X_st rnd d_c val                     71           100  0.422028   \n",
       "spatial X_st min d_c train                   24            98  0.422028   \n",
       "spatial X_st min d_c val                     24            98  0.422028   \n",
       "spatial X_st max d_c train                   17            48  0.422028   \n",
       "spatial X_st max d_c val                     17            48  0.422028   \n",
       "spatial X_st avg d_c train                   18            47  0.422028   \n",
       "spatial X_st avg d_c val                     18            47  0.422028   \n",
       "spatial X_(t,s) rnd d_c train                77           100  0.422028   \n",
       "spatial X_(t,s) rnd d_c val                  77           100  0.422028   \n",
       "spatial X_(t,s) min d_c train                74           100  0.422028   \n",
       "spatial X_(t,s) min d_c val                  74           100  0.422028   \n",
       "spatial X_(t,s) max d_c train                51            83  0.422028   \n",
       "spatial X_(t,s) max d_c val                  51            83  0.422028   \n",
       "spatial X_(t,s) avg d_c train                62           100  0.422028   \n",
       "spatial X_(t,s) avg d_c val                  62           100  0.422028   \n",
       "spatial Y_hat_(t,s) rnd d_c train            49            98  0.422028   \n",
       "spatial Y_hat_(t,s) rnd d_c val              49            98  0.422028   \n",
       "spatial Y_hat_(t,s) min d_c train            49            95  0.422028   \n",
       "spatial Y_hat_(t,s) min d_c val              49            95  0.422028   \n",
       "spatial Y_hat_(t,s) max d_c train            38            80  0.422028   \n",
       "spatial Y_hat_(t,s) max d_c val              38            80  0.422028   \n",
       "spatial Y_hat_(t,s) avg d_c train            40            84  0.422028   \n",
       "spatial Y_hat_(t,s) avg d_c val              40            84  0.422028   \n",
       "spatial Y_(t,s) rnd d_c train                42            92  0.422028   \n",
       "spatial Y_(t,s) rnd d_c val                  42            92  0.422028   \n",
       "spatial Y_(t,s) min d_c train                27            63  0.422028   \n",
       "spatial Y_(t,s) min d_c val                  27            63  0.422028   \n",
       "spatial Y_(t,s) max d_c train                23            57  0.422028   \n",
       "spatial Y_(t,s) max d_c val                  23            57  0.422028   \n",
       "spatial Y_(t,s) avg d_c train                25            64  0.422028   \n",
       "spatial Y_(t,s) avg d_c val                  25            64  0.422028   \n",
       "\n",
       "Unnamed: 0                         test_loss  accuracy  \n",
       "spatial None PL train               0.488721         0  \n",
       "spatial None PL val                 0.488721         0  \n",
       "spatial X_st rnd d_c train          0.229853        46  \n",
       "spatial X_st rnd d_c val            0.229853        46  \n",
       "spatial X_st min d_c train          0.344245        18  \n",
       "spatial X_st min d_c val            0.344245        18  \n",
       "spatial X_st max d_c train          0.344956        18  \n",
       "spatial X_st max d_c val            0.344956        18  \n",
       "spatial X_st avg d_c train          0.336658        20  \n",
       "spatial X_st avg d_c val            0.336658        20  \n",
       "spatial X_(t,s) rnd d_c train       0.119214        72  \n",
       "spatial X_(t,s) rnd d_c val         0.119214        72  \n",
       "spatial X_(t,s) min d_c train       0.152110        64  \n",
       "spatial X_(t,s) min d_c val         0.152110        64  \n",
       "spatial X_(t,s) max d_c train       0.160277        62  \n",
       "spatial X_(t,s) max d_c val         0.160277        62  \n",
       "spatial X_(t,s) avg d_c train       0.126024        70  \n",
       "spatial X_(t,s) avg d_c val         0.126024        70  \n",
       "spatial Y_hat_(t,s) rnd d_c train   0.076669        82  \n",
       "spatial Y_hat_(t,s) rnd d_c val     0.076669        82  \n",
       "spatial Y_hat_(t,s) min d_c train   0.090226        79  \n",
       "spatial Y_hat_(t,s) min d_c val     0.090226        79  \n",
       "spatial Y_hat_(t,s) max d_c train   0.115200        73  \n",
       "spatial Y_hat_(t,s) max d_c val     0.115200        73  \n",
       "spatial Y_hat_(t,s) avg d_c train   0.085773        80  \n",
       "spatial Y_hat_(t,s) avg d_c val     0.085773        80  \n",
       "spatial Y_(t,s) rnd d_c train       0.144567        66  \n",
       "spatial Y_(t,s) rnd d_c val         0.144567        66  \n",
       "spatial Y_(t,s) min d_c train       0.274123        35  \n",
       "spatial Y_(t,s) min d_c val         0.274123        35  \n",
       "spatial Y_(t,s) max d_c train       0.304108        28  \n",
       "spatial Y_(t,s) max d_c val         0.304108        28  \n",
       "spatial Y_(t,s) avg d_c train       0.285902        32  \n",
       "spatial Y_(t,s) avg d_c val         0.285902        32  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        result = results_list[result_index_counter]\n",
    "        \n",
    "        # perform some transformations on result\n",
    "        results_transformed = (\n",
    "            result[2:7].set_index('Unnamed: 0').transpose()\n",
    "        )\n",
    "        results_transformed = (\n",
    "            results_transformed.drop(['streamtime_usage'], axis=1)\n",
    "        )\n",
    "        results_transformed['test_loss'] = (\n",
    "            results_transformed['test_loss']\n",
    "        )\n",
    "        results_transformed['RF_loss'] = (\n",
    "            results_transformed['RF_loss']\n",
    "        )\n",
    "        results_transformed['accuracy'] = (\n",
    "            100 * (1 - np.minimum(1, results_transformed['test_loss'] /results_transformed['RF_loss']))\n",
    "        ).round().astype(int)\n",
    "        results_transformed['sensor_usage'] = (\n",
    "            (100 * results_transformed['sensor_usage']).round().astype(int)\n",
    "        )\n",
    "        results_transformed['budget_usage'] = (\n",
    "            (100 * results_transformed['budget_usage']).round().astype(int)\n",
    "        )\n",
    "        \n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        print(parameter)\n",
    "        display(results_transformed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Space and time selection\n",
    "\n",
    "Here, we visualize which points in time and space were queried during the experiments by our active learning and passive learning algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "# define some hyper for plots\n",
    "n_iter_plot = 3\n",
    "n_meshes_surface = 10\n",
    "\n",
    "# import building meta data\n",
    "path_to_building_meta = '../data/private/' + profile_set + '/meta/meta buildings.csv'\n",
    "building_meta = pd.read_csv(path_to_building_meta)\n",
    "\n",
    "def create_bottom_plot(first_colname, df_initial_sensors):\n",
    "    \n",
    "    ax.set_title(first_colname)\n",
    "\n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df_initial_sensors['building lat'].min()\n",
    "    max_lat = df_initial_sensors['building lat'].max() \n",
    "    min_long = df_initial_sensors['building long'].min()\n",
    "    max_long = df_initial_sensors['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    map_height = 0\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df_initial_sensors['building long'], \n",
    "        df_initial_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    ) \n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(map_height)\n",
    "    \n",
    "def create_plot(time_data, df, df_new_sensors):\n",
    "    \n",
    "    # get bound coordinates of all buildings\n",
    "    min_lat = df['building lat'].min()\n",
    "    max_lat = df['building lat'].max() \n",
    "    min_long = df['building long'].min()\n",
    "    max_long = df['building long'].max()\n",
    "\n",
    "    # create evenly sized arrays and meshed grid of lats and longs\n",
    "    lat_surface = np.linspace(\n",
    "        min_lat, \n",
    "        max_lat,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface = np.linspace(\n",
    "        min_long, \n",
    "        max_long,\n",
    "        num=n_meshes_surface\n",
    "    )\n",
    "    long_surface, lat_surface  = np.meshgrid(long_surface, lat_surface)\n",
    "    \n",
    "    # update max time point\n",
    "    min_time_point, max_time_point = min(time_data), max(time_data)\n",
    "    map_height = max_time_point/3 * (1 + 3* iteration/n_iter_plot)\n",
    "    shifting_time = max_time_point - map_height\n",
    "    Z = np.full((len(lat_surface), 1), map_height)\n",
    "    \n",
    "    ax.scatter(\n",
    "        df['building long'], \n",
    "        df['building lat'], \n",
    "        time_data - shifting_time, \n",
    "        c=time_data, alpha=0.7\n",
    "    )\n",
    "    ax.scatter(\n",
    "        df_new_sensors['building long'], \n",
    "        df_new_sensors['building lat'], \n",
    "        map_height,  \n",
    "        alpha=1, marker='x', c='r', s=100\n",
    "    )\n",
    "    ax.plot_surface(\n",
    "        long_surface, \n",
    "        lat_surface, \n",
    "        Z,  \n",
    "        alpha=0.03\n",
    "    )\n",
    "    ax.set_zlim(min_time_point - shifting_time, max_time_point)\n",
    "    \n",
    "    \n",
    "def customize_plot(iteration=None):\n",
    "    \n",
    "    # set angle\n",
    "    ax.view_init(30, 103)\n",
    "    \n",
    "    # Get rid of the panes\n",
    "    ax.w_xaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_yaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "    ax.w_zaxis.set_pane_color((1.0, 1.0, 1.0, 0.0))\n",
    "\n",
    "    # Get rid of the ticks\n",
    "    ax.set_xticks([]) \n",
    "    ax.set_yticks([]) \n",
    "    ax.set_zticks([])\n",
    "\n",
    "    # Add the labels\n",
    "    ax.set_xlabel('longitude' )\n",
    "    ax.set_ylabel('latitude')\n",
    "    ax.set_zlabel('time')\n",
    "\n",
    "    # shift time (z) axis\n",
    "    tmp_planes = ax.zaxis._PLANES \n",
    "    ax.zaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    # shift lat (y) axis\n",
    "    ax.yaxis._PLANES = ( \n",
    "        tmp_planes[2], tmp_planes[3], \n",
    "        tmp_planes[0], tmp_planes[1], \n",
    "        tmp_planes[4], tmp_planes[5]\n",
    "    )\n",
    "    \n",
    "    \n",
    "    # set subplot titles\n",
    "    if iteration is not None:\n",
    "        ax.set_title(fig_title_list[plot_counter-1])\n",
    "        \n",
    "\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        spacetime_result = spacetime_selection_list[result_index_counter]\n",
    "\n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        for AL_variable in AL_VARIABLES:\n",
    "            \n",
    "            for AL_variant in AL_VARIANTS:\n",
    "        \n",
    "                # create figure\n",
    "                fig = plt.figure(figsize=(16, (n_iter_plot+1) * 8))\n",
    "\n",
    "                # set the fontsize for figures\n",
    "                mpl.rcParams.update({'font.size': 16}) #FONTSIZE\n",
    "\n",
    "                colname_initial_sensors = '{} - initial sensors'.format(pred_type)\n",
    "                intial_sensors = spacetime_result[colname_initial_sensors]\n",
    "                df_initial_sensors = pd.DataFrame({'building ID':intial_sensors})\n",
    "                df_initial_sensors = df_initial_sensors.merge(building_meta, on='building ID', how='left')\n",
    "                \n",
    "                plot_counter= 1\n",
    "                ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                create_bottom_plot(\n",
    "                    'Active learning (AL) \\n a.',\n",
    "                    df_initial_sensors\n",
    "                )\n",
    "                customize_plot()\n",
    "                plot_counter += 1\n",
    "                ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                create_bottom_plot(\n",
    "                    'Passive learning (PL) \\n b.',\n",
    "                    df_initial_sensors\n",
    "                )\n",
    "                customize_plot()\n",
    "                plot_counter += 1\n",
    "                old_senors_AL_set = set(intial_sensors)\n",
    "                old_senors_PL_set = set(intial_sensors)\n",
    "                new_sensors_PL_set = set()\n",
    "                new_sensors_AL_set = set()\n",
    "                for iteration in range(n_iter_plot):\n",
    "\n",
    "                    # create column names\n",
    "                    colname_AL_times = '{} {} {} - iter {} time'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    colname_AL_spaces = '{} {} {} - iter {} space'.format(pred_type, AL_variable, AL_variant, iteration) \n",
    "                    colname_PL_times = '{} None PL - iter {} time'.format(pred_type, iteration)\n",
    "                    colname_PL_spaces = '{} None PL - iter {} space'.format(pred_type, iteration)\n",
    "                    \n",
    "                    ### Plot AL results on left column ###\n",
    "                    \n",
    "                    # get data\n",
    "                    space_data_AL = spacetime_result[colname_AL_spaces]\n",
    "                    time_data_AL = spacetime_result[colname_AL_times]\n",
    "                    space_data_PL = spacetime_result[colname_PL_spaces]\n",
    "                    time_data_PL = spacetime_result[colname_PL_times]\n",
    "\n",
    "                    # get new sensors and set old sensors\n",
    "                    old_senors_AL_set = new_sensors_AL_set\n",
    "                    new_sensors_AL_set = set(space_data_AL).union(old_senors_AL_set)\n",
    "                    new_sensors_AL_list = list(new_sensors_AL_set - old_senors_AL_set)\n",
    "                    old_senors_PL_set = new_sensors_PL_set\n",
    "                    new_sensors_PL_set = set(space_data_PL).union(old_senors_PL_set)\n",
    "                    new_sensors_PL_list = list(new_sensors_PL_set - old_senors_PL_set)\n",
    "\n",
    "                    # assign lat and long to building IDs\n",
    "                    df_AL = pd.DataFrame({'building ID':space_data_AL})\n",
    "                    df_AL = df_AL.merge(building_meta, on='building ID', how='left')\n",
    "                    df_PL = pd.DataFrame({'building ID':space_data_PL})\n",
    "                    df_PL = df_PL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    df_new_sensors_AL = pd.DataFrame({'building ID':new_sensors_AL_list})\n",
    "                    df_new_sensors_AL = df_new_sensors_AL.merge(building_meta, on='building ID', how='left')\n",
    "                    df_new_sensors_PL = pd.DataFrame({'building ID':new_sensors_PL_list})\n",
    "                    df_new_sensors_PL = df_new_sensors_PL.merge(building_meta, on='building ID', how='left')\n",
    "\n",
    "                    # AL temporal scatter plot\n",
    "                    ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                    create_plot(time_data_AL, df_AL, df_new_sensors_AL)\n",
    "                    customize_plot(iteration)\n",
    "                    plot_counter += 1\n",
    "\n",
    "                    # PL temporal scatter plot\n",
    "                    ax = fig.add_subplot((n_iter_plot+1), 2, plot_counter, projection='3d')\n",
    "                    create_plot(time_data_PL, df_PL, df_new_sensors_PL)\n",
    "                    customize_plot(iteration)\n",
    "                    plot_counter+= 1\n",
    "\n",
    "\n",
    "                # create saving paths \n",
    "                saving_path = (\n",
    "                    path_to_saving_spacetime \n",
    "                    + pred_type\n",
    "                    + ' '\n",
    "                    + parameter\n",
    "                    + ' '\n",
    "                    + AL_variable\n",
    "                    + ' '\n",
    "                    + AL_variant\n",
    "                    + '.pdf'\n",
    "                )\n",
    "\n",
    "                # create a legend\n",
    "                legend_elements = [\n",
    "                    Line2D([0], [0], marker='o', color='w', markerfacecolor='b', markersize=10, label='data point query in space-time'),\n",
    "                    Line2D([0], [0], marker='X', color='w', markerfacecolor='r', markersize=15, label='new sensor query in space')\n",
    "                ]\n",
    "\n",
    "                # set layout tight\n",
    "                fig.tight_layout()\n",
    "\n",
    "                fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.5,1))\n",
    "\n",
    "                # save figures\n",
    "                fig.savefig(saving_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Budget vs. accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "for AL_variable in AL_VARIABLES:\n",
    "    for AL_variant in AL_VARIANTS:\n",
    "        \n",
    "        # set the fontsize for figures\n",
    "        mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "        fig, ax = plt.subplots(\n",
    "            len(PRED_TYPE_LIST), \n",
    "            2, \n",
    "            figsize=(\n",
    "                20, \n",
    "                24\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # set plot_counter for subplot title setting\n",
    "        plot_counter = 0\n",
    "\n",
    "        # create a counter over the list of numeric results\n",
    "        result_index_counter = 0\n",
    "\n",
    "        # iterate over all considered prediction types\n",
    "        for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "\n",
    "            # iterate over all considered parameter constellations\n",
    "            for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "\n",
    "                delta = int(parameter[5])\n",
    "                valup = int(parameter[12])\n",
    "\n",
    "                # skip cases where we validate against queried data too\n",
    "                if valup == 0:\n",
    "                    # increment result index counter\n",
    "                    result_index_counter += 1\n",
    "                    continue\n",
    "\n",
    "                # get results df corresponding to currently iterated parameter and pred_type\n",
    "                budgetaccuracy = budgetaccuracy_list[result_index_counter]\n",
    "\n",
    "                # increment result index counter\n",
    "                result_index_counter += 1\n",
    "\n",
    "                # create the column name for PL lossess\n",
    "                col_name_data = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'data'\n",
    "                )\n",
    "                col_name_sensors = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'sensors'\n",
    "                )\n",
    "                col_name_streamtimes = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'streamtimes'\n",
    "                )\n",
    "                col_name_accuracy = (\n",
    "                    pred_type \n",
    "                    + ' None ' \n",
    "                    + 'PL ' \n",
    "                    + 'accuracy'\n",
    "                )\n",
    "\n",
    "                # get PL results\n",
    "                PL_data = np.append(0, budgetaccuracy[col_name_data].values)\n",
    "                PL_accuracy = np.append(0, budgetaccuracy[col_name_accuracy].values)\n",
    "\n",
    "                # create the column name for iterated validation loss\n",
    "                col_name_data = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' data'\n",
    "                )\n",
    "                col_name_accuracy = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' accuracy'\n",
    "                )\n",
    "\n",
    "                # get training losses for mode 1 with validation updates\n",
    "                AL_data = np.append(0, budgetaccuracy[col_name_data].values)\n",
    "                AL_accuracy = np.append(0, budgetaccuracy[col_name_accuracy].values)\n",
    "\n",
    "                # plot iterated training losses\n",
    "                ax[index_pred, delta].plot(\n",
    "                    AL_accuracy,\n",
    "                    color='b'\n",
    "                )\n",
    "\n",
    "                for x,y in enumerate(AL_accuracy):\n",
    "\n",
    "                    # plot annotations only on every second step\n",
    "                    if (x+1)%2 == 0:\n",
    "                        ax[index_pred, delta].annotate(\n",
    "                            str(AL_data[x])+'%',\n",
    "                            (x, y+5)\n",
    "                        )\n",
    "\n",
    "                # plot PL accuracy.\n",
    "                # Note: Moved plotting down after plotting AL, in order to have legends aligned with height of plots\n",
    "                ax[index_pred, delta].plot(\n",
    "                    PL_accuracy, \n",
    "                    color='r',\n",
    "                )\n",
    "\n",
    "                ax[index_pred, delta].set_ylim(\n",
    "                    top=100\n",
    "                )\n",
    "\n",
    "                for x,y in enumerate(PL_accuracy):\n",
    "                    # plot annotations only on every second step\n",
    "                    if (x+1)%2 == 0:\n",
    "                        ax[index_pred, delta].annotate(\n",
    "                            str(PL_data[x])+'%',\n",
    "                            (x, y-5)\n",
    "                        )\n",
    "\n",
    "                \n",
    "                # set subplot titles\n",
    "                ax[index_pred, delta].set_title(fig_title_list[plot_counter])\n",
    "                plot_counter+= 1\n",
    "                \n",
    "                # set y-axis labels\n",
    "                ax[index_pred, 0].set_ylabel(\n",
    "                    '{} \\n prediction accuracy'.format(pred_type), \n",
    "                    fontsize=FONTSIZE\n",
    "                )\n",
    "\n",
    "                # set x-axis\n",
    "                ax[len(PRED_TYPE_LIST)-1, delta].set_xlabel(\n",
    "                    'data selection \\n iteration', \n",
    "                    fontsize=FONTSIZE\n",
    "                )\n",
    "\n",
    "\n",
    "        # set column titles\n",
    "        cols = [\n",
    "            'δ=0 \\n a.', \n",
    "            'δ=1 \\n b.'\n",
    "        ]\n",
    "        for axes, col in zip(ax[0], cols):\n",
    "            axes.set_title(col)\n",
    "\n",
    "        # create saving paths \n",
    "        saving_path = (\n",
    "            path_to_saving_budgetvsaccuracy \n",
    "            + AL_variable\n",
    "            + ' '\n",
    "            + AL_variant\n",
    "            + '.pdf'\n",
    "        )\n",
    "\n",
    "        legend_elements = [Line2D([0], [0], color='b', label='Active learning (AL)', markersize=FONTSIZE),\n",
    "                           Line2D([0], [0], color='r', label='Passive learning (PL)', markersize=FONTSIZE),\n",
    "                           Line2D([0], [0], color='w', label='% = budget usage', markersize=FONTSIZE)]\n",
    "\n",
    "        # set layout tight\n",
    "        fig.tight_layout()\n",
    "\n",
    "        fig.legend(handles=legend_elements, loc='upper center', bbox_to_anchor=(0.9,1.02))\n",
    "\n",
    "        # save figures\n",
    "        fig.savefig(saving_path, bbox_inches=\"tight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Training and validation losses against unqueried candidates\n",
    "\n",
    "For each prediction task, each query variable and each query variant, we create figures that allow us to compare their training and validation losses throughout the process of querying new candidate data points in each iteration of the algorithm that we propose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "### Define a series of manual corrections for figures ###\n",
    "\n",
    "class ManualFigureCorrections:\n",
    "    \n",
    "    \"\"\" Bundles information for manually correcting figure axes \"\"\"\n",
    "    \n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        pred_type, \n",
    "        AL_variable_list, \n",
    "        parameter, \n",
    "        column, \n",
    "        y_lim_bottom, \n",
    "        y_lim_top\n",
    "    ):\n",
    "        \n",
    "        \"\"\" Takes required arguments for correcting axes. \"\"\"\n",
    "        \n",
    "        self.pred_type = pred_type\n",
    "        self.AL_variable_list = AL_variable_list\n",
    "        self.parameter = parameter\n",
    "        self.column = column\n",
    "        self.y_lim_bottom = y_lim_bottom\n",
    "        self.y_lim_top = y_lim_top\n",
    "        \n",
    "correction_list = []\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        'delta0_valup1', \n",
    "        0,\n",
    "        0,\n",
    "        9\n",
    "    )\n",
    ")\n",
    "\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        'delta0_valup1', \n",
    "        1,\n",
    "        0.2,\n",
    "        2.0\n",
    "    )\n",
    ")\n",
    "\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        'delta1_valup1', \n",
    "        0,\n",
    "        0,\n",
    "        3\n",
    "    )\n",
    ")\n",
    "\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        'delta1_valup1', \n",
    "        1,\n",
    "        0,\n",
    "        1\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# set the fontsize for figures\n",
    "mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "\n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12])\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        result = results_list[result_index_counter]\n",
    "        \n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        # create the column name for random lossess\n",
    "        col_name_train = (\n",
    "            pred_type \n",
    "            + ' None ' \n",
    "            + 'PL ' \n",
    "            + 'train'\n",
    "        )\n",
    "        col_name_val = (\n",
    "            pred_type \n",
    "            + ' None ' \n",
    "            + 'PL ' \n",
    "            + 'val'\n",
    "        )\n",
    "        \n",
    "        \n",
    "        # get random results\n",
    "        PL_train = result[col_name_train][9:].dropna().values\n",
    "        t_iter = int(result[col_name_train][1])\n",
    "\n",
    "        PL_val = result[col_name_val][9:].dropna().values\n",
    "        budget_usage = result[col_name_val][2]\n",
    "        sensor_usage = result[col_name_val][3]\n",
    "        RF_loss = result[col_name_val][5]\n",
    "        PL_loss = result[col_name_val][6]\n",
    "        PL_accuracy = round(100* (1 - PL_loss/RF_loss))/100\n",
    "        \n",
    "        # create the figure legends for random losses\n",
    "        legend_RF = 'RF baseline'\n",
    "        legend_PL_train = '{} {}s'.format(\n",
    "            'PL random:', \n",
    "            t_iter\n",
    "        )\n",
    "        legend_PL_val = '{}  {:.0%} data  {:.0%} sensors  {:.0%} accuracy'.format(\n",
    "            'PL random:', \n",
    "            budget_usage, \n",
    "            sensor_usage,\n",
    "            PL_loss\n",
    "        )\n",
    "        \n",
    "        fig, ax = plt.subplots(\n",
    "            len(AL_VARIABLES), \n",
    "            2, \n",
    "            figsize=(\n",
    "                20, \n",
    "                len(AL_VARIABLES) * WIDTH_FACTOR\n",
    "            )\n",
    "        )\n",
    "        \n",
    "        # set figure titles\n",
    "        if valup == 0:\n",
    "\n",
    "            string_valup = 'initial'\n",
    "\n",
    "        else:\n",
    "\n",
    "            string_valup = 'unqueried'\n",
    "        \n",
    "        # counter to increment subtitle of figures\n",
    "        title_counter = 0\n",
    "        \n",
    "        # iterate over all AL variables\n",
    "        for index_var, AL_variable in enumerate(AL_VARIABLES):\n",
    "            \n",
    "            # plot passive learning losses\n",
    "            ax[index_var, 0].plot(\n",
    "                PL_train, \n",
    "                color='b', \n",
    "                linestyle='--', \n",
    "                label=legend_PL_train\n",
    "            )\n",
    "            ax[index_var, 1].plot(\n",
    "                PL_val, \n",
    "                color='b', \n",
    "                linestyle='--', \n",
    "                label=legend_PL_val\n",
    "            )\n",
    "                       \n",
    "            # iterate over all AL variants\n",
    "            for index_method, AL_variant in enumerate(AL_VARIANTS):\n",
    "                \n",
    "                # create the column name for iterated validation loss\n",
    "                col_name_train = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' train'\n",
    "                )\n",
    "                col_name_val = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' val'\n",
    "                )\n",
    "                \n",
    "                # get training losses for mode 1 with validation updates\n",
    "                train_history = result[col_name_train][9:].dropna().values\n",
    "                t_iter = int(result[col_name_train][1])\n",
    "\n",
    "                val_history = result[col_name_val][9:].dropna().values\n",
    "                budget = result[col_name_val][2]\n",
    "                sensor = result[col_name_val][3]\n",
    "                RF_loss = result[col_name_val][5]\n",
    "                AL_loss = result[col_name_val][6]\n",
    "                AL_accuracy = round(100* (1 - AL_loss/RF_loss))/100\n",
    "                \n",
    "                # create the legends\n",
    "                legend_train = 'AL {}: {}s'.format(\n",
    "                    AL_variant, \n",
    "                    t_iter\n",
    "                )\n",
    "                legend_val = 'AL {}:  {:.0%} data  {:.0%} sensors  {:.0%} accuracy'.format(\n",
    "                    AL_variant, \n",
    "                    budget, \n",
    "                    sensor,\n",
    "                    AL_accuracy\n",
    "                )\n",
    "                \n",
    "                # plot iterated training losses\n",
    "                ax[index_var, 0].plot(\n",
    "                    train_history, \n",
    "                    label=legend_train\n",
    "                )\n",
    "                ax[index_var, 1].plot(\n",
    "                    val_history, \n",
    "                    label=legend_val\n",
    "                )\n",
    "\n",
    "            # set legend\n",
    "            ax[index_var, 0].legend(\n",
    "                loc='best', \n",
    "                frameon=False,\n",
    "                fontsize=FONTSIZE-2\n",
    "            )\n",
    "            ax[index_var, 1].legend(\n",
    "                loc='best', \n",
    "                frameon=False,\n",
    "                fontsize=FONTSIZE-2\n",
    "            )\n",
    "\n",
    "            # set y-axis labels\n",
    "            ax[index_var, 0].set_ylabel(\n",
    "                'L2 loss [kW²]', \n",
    "                fontsize=FONTSIZE+3\n",
    "            )\n",
    "            \n",
    "            \"\"\"\n",
    "            # set y-axis limits\n",
    "            for correction in correction_list:\n",
    "\n",
    "                if correction.pred_type != pred_type:\n",
    "                    continue\n",
    "\n",
    "                if correction.parameter != parameter:\n",
    "                    continue\n",
    "\n",
    "                if AL_variable in correction.AL_variable_list:\n",
    "\n",
    "                    ax[index_var, correction.column].set_ylim(\n",
    "                        bottom=correction.y_lim_bottom,\n",
    "                        top=correction.y_lim_top\n",
    "                    )\n",
    "            \"\"\"\n",
    "            \n",
    "            # set title\n",
    "            ax[index_var, 0].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "            ax[index_var, 1].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "            \n",
    "        # set x-axis\n",
    "        ax[index_var, 0].set_xlabel(\n",
    "            'epoch', \n",
    "            fontsize=FONTSIZE+3\n",
    "        )\n",
    "        ax[index_var, 1].set_xlabel(\n",
    "            'epoch', \n",
    "            fontsize=FONTSIZE+3\n",
    "        )\n",
    "\n",
    "        # set column titles\n",
    "        cols = [\n",
    "            'Training losses \\n a.', \n",
    "            'Validation losses \\n b.'\n",
    "        ]\n",
    "        for axes, col in zip(ax[0], cols):\n",
    "            axes.set_title(col)\n",
    "\n",
    "\n",
    "        # create saving paths \n",
    "        saving_path = (\n",
    "            path_to_saving_lossesvsunqueried \n",
    "            + pred_type \n",
    "            + ' ' \n",
    "            + parameter \n",
    "            + '.pdf'\n",
    "        )\n",
    "\n",
    "        # set layout tight\n",
    "        fig.tight_layout()\n",
    "\n",
    "        # save figures\n",
    "        fig.savefig(saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Validation losses against all candidates\n",
    "\n",
    "Here, we compare the validation losses for both removing candidate data points and keeping them after these are queried against the initial candidate data pool. This has the purpose to see how each variant of the algorithm that we propose deals with biases when extending the initial prediction model with newly queried data points. We only compare validation losses and neglect training losses to be more concise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "### Define a set of manual corrections for figures ###\n",
    "\n",
    "correction_list = []\n",
    "\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        None, \n",
    "        0,\n",
    "        0.5,\n",
    "        2.3\n",
    "    )\n",
    ")\n",
    "correction_list.append(\n",
    "    ManualFigureCorrections(\n",
    "        'spatio-temporal', \n",
    "        [\n",
    "            'X_st', \n",
    "            'X_(t,s)', \n",
    "            'Y_(t,s)'\n",
    "        ], \n",
    "        None, \n",
    "        1,\n",
    "        0.25,\n",
    "        2.4\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# set the fontsize for figures\n",
    "mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "    \n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # create figure\n",
    "    fig, ax = plt.subplots(\n",
    "        len(AL_VARIABLES), \n",
    "        2, \n",
    "        figsize=(\n",
    "            20, \n",
    "            len(AL_VARIABLES) * WIDTH_FACTOR\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "    \n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12])\n",
    "\n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        result = results_list[result_index_counter]\n",
    "        \n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        # skip results, if we consider valup == 0\n",
    "        if valup == 1:\n",
    "            continue\n",
    "        if delta == 1:\n",
    "            plot_column = 0\n",
    "        else:\n",
    "            plot_column = 1\n",
    "            \n",
    "        # create the column name for PL validation loss\n",
    "        col_name_val = (\n",
    "            pred_type \n",
    "            + ' None ' \n",
    "            + 'PL ' \n",
    "            + 'val'\n",
    "        )\n",
    "\n",
    "        PL_val = result[col_name_val][9:].dropna().values\n",
    "        budget_usage = result[col_name_val][2]\n",
    "        sensor_usage = result[col_name_val][3]\n",
    "        RF_loss = result[col_name_val][5]\n",
    "        PL_loss = result[col_name_val][6]\n",
    "        PL_accuracy = round(100* (1 - PL_loss/RF_loss))/100\n",
    "        \n",
    "        # create the figure legends for random losses\n",
    "        legend_RF = 'RF baseline'\n",
    "        legend_PL_val = 'PL random {:.0%} data  {:.0%} sensors  {:.0%} accuracy'.format(\n",
    "             budget_usage, \n",
    "             sensor_usage,\n",
    "             PL_accuracy\n",
    "        )\n",
    "        \n",
    "        title_counter = 0\n",
    "        \n",
    "        # iterate over all sort variables\n",
    "        for index_var, AL_variable in enumerate(AL_VARIABLES):\n",
    "\n",
    "            # plot passive learning training losses\n",
    "            ax[index_var, plot_column].plot(\n",
    "                PL_val, \n",
    "                color='b', \n",
    "                linestyle='--', \n",
    "                label=legend_PL_val\n",
    "            )\n",
    "\n",
    "            # iterate over all methods of currently iterated sort variable\n",
    "            for index_method, method in enumerate(AL_VARIANTS):\n",
    "\n",
    "                # create the column name for iterated validation loss\n",
    "                col_name_val = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + method \n",
    "                    + ' val'\n",
    "                )\n",
    "                \n",
    "                val_history = result[col_name_val][9:].dropna().values\n",
    "                budget = result[col_name_val][2]\n",
    "                sensor = result[col_name_val][3]\n",
    "                RF_loss = result[col_name_val][5]\n",
    "                AL_loss = result[col_name_val][6]\n",
    "                AL_accuracy = round(100* (1 - AL_loss/RF_loss))/100\n",
    "                \n",
    "                # create the legends\n",
    "                legend_val = 'AL {}  {:.0%} data  {:.0%} sensors  {:.0%} accuracy'.format(\n",
    "                    method, \n",
    "                    budget, \n",
    "                    sensor, \n",
    "                    AL_accuracy\n",
    "                )\n",
    "          \n",
    "                # plot iterated validation losses\n",
    "                ax[index_var, plot_column].plot(\n",
    "                    val_history, \n",
    "                    label=legend_val\n",
    "                )\n",
    "                \n",
    "                # set legends\n",
    "                ax[index_var, plot_column].legend(\n",
    "                    loc='best', \n",
    "                    frameon=False,\n",
    "                    fontsize=FONTSIZE-2\n",
    "                )\n",
    "\n",
    "                # set y-axis labels\n",
    "                ax[index_var, plot_column].set_ylabel(\n",
    "                    'L2 loss [kW²]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                \n",
    "                \"\"\"\n",
    "                # set y-axis limits\n",
    "                for correction in correction_list:\n",
    "\n",
    "                    if correction.pred_type != pred_type:\n",
    "                        continue\n",
    "\n",
    "                    if AL_variable in correction.AL_variable_list:\n",
    "\n",
    "                        ax[index_var, correction.column].set_ylim(\n",
    "                            bottom=correction.y_lim_bottom,\n",
    "                            top=correction.y_lim_top\n",
    "                        )\n",
    "                \"\"\"\n",
    "                \n",
    "            # set title\n",
    "            ax[index_var, 0].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "            ax[index_var, 1].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "            \n",
    "        # set x-axis labels\n",
    "        ax[index_var, plot_column].set_xlabel(\n",
    "            'epoch', \n",
    "            fontsize=FONTSIZE+3\n",
    "        )\n",
    "\n",
    "    # set column titles\n",
    "    cols = [\n",
    "        'Validation losses with δ=1 \\n a.', \n",
    "        'Validation losses with δ=0 \\n b.'\n",
    "    ]\n",
    "    for axes, col in zip(ax[0], cols):\n",
    "        axes.set_title(col)\n",
    "\n",
    "    # set layout tight\n",
    "    fig.tight_layout()\n",
    "\n",
    "    # create saving paths \n",
    "    saving_path = (\n",
    "        path_to_saving_lossesvsall \n",
    "        + pred_type \n",
    "        + '.pdf'\n",
    "    )\n",
    "\n",
    "    # save figures\n",
    "    fig.savefig(saving_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Query sequence importance\n",
    "\n",
    "Here, we compare the training and validation losses of our active learning models against learning from the same data but in a randomized sequence. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "# set the fontsize for figures\n",
    "mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "# create list of custom lines for custom legend\n",
    "custom_lines = [\n",
    "    Line2D([0], [0], color='b', linestyle=\"--\"),\n",
    "    Line2D([0], [0], color='b')\n",
    "]\n",
    "\n",
    "# create color list for plots of same AL variant to have same color\n",
    "color_list = [\n",
    "    '#1f77b4', '#ff7f0e', '#2ca02c', '#d62728', '#9467bd', \n",
    "    '#8c564b',  '#e377c2', '#7f7f7f', '#bcbd22', '#17becf'\n",
    "]\n",
    "\n",
    "# create a counter over the list of numeric results\n",
    "result_index_counter = 0\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    fig_valup0, ax_valup0 = plt.subplots(\n",
    "        len(AL_VARIABLES), \n",
    "        2, \n",
    "        figsize=(\n",
    "            20, \n",
    "            len(AL_VARIABLES) * WIDTH_FACTOR\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    fig_valup1, ax_valup1 = plt.subplots(\n",
    "        len(AL_VARIABLES), \n",
    "        2, \n",
    "        figsize=(\n",
    "            20, \n",
    "            len(AL_VARIABLES) * WIDTH_FACTOR\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "\n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12])\n",
    "        \n",
    "        # get results df corresponding to currently iterated parameter and pred_type\n",
    "        AL_result = results_list[\n",
    "            result_index_counter\n",
    "        ]\n",
    "        seqimportance_result = seqimportance_list[\n",
    "            result_index_counter\n",
    "        ]\n",
    "        \n",
    "        # increment result index counter\n",
    "        result_index_counter += 1\n",
    "        \n",
    "        # set wanted plot column\n",
    "        if delta == 1:\n",
    "            plot_column = 0\n",
    "        else:\n",
    "            plot_column = 1\n",
    "        \n",
    "        if valup == 0:\n",
    "            fig = fig_valup0\n",
    "            ax = ax_valup0\n",
    "        else:\n",
    "            fig = fig_valup1\n",
    "            ax = ax_valup1\n",
    "        \n",
    "        title_counter = 0\n",
    "        # iterate over all AL variables\n",
    "        for index_var, AL_variable in enumerate(AL_VARIABLES):\n",
    "            \n",
    "            # iterate over all AL variants\n",
    "            for index_method, AL_variant in enumerate(AL_VARIANTS):\n",
    "                \n",
    "                # create the column name for iterated validation loss\n",
    "                col_name_val = (\n",
    "                    pred_type \n",
    "                    + ' ' \n",
    "                    + AL_variable \n",
    "                    + ' ' \n",
    "                    + AL_variant \n",
    "                    + ' val'\n",
    "                )\n",
    "                \n",
    "                # get validation losses for AL\n",
    "                AL_val_history = (\n",
    "                    AL_result[col_name_val][9:].dropna().values\n",
    "                )\n",
    "                \n",
    "                # get validation losses with randomized sequence tests\n",
    "                seqimportance_val_history = (\n",
    "                    seqimportance_result[col_name_val][1:].dropna().values\n",
    "                )\n",
    "                \n",
    "                # plot iterated losses\n",
    "                ax[index_var, plot_column].plot(\n",
    "                    AL_val_history, \n",
    "                    color=color_list[index_method]\n",
    "                )\n",
    "                ax[index_var, plot_column].plot(\n",
    "                    seqimportance_val_history, \n",
    "                    color=color_list[index_method], \n",
    "                    linestyle=\"--\"\n",
    "                )\n",
    "                \n",
    "                # set y-axis labels\n",
    "                ax[index_var, 0].set_ylabel(\n",
    "                    'L2 loss [kW²]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                \n",
    "            # set title\n",
    "            ax[index_var, 0].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "            ax[index_var, 1].set_title(fig_title_list[title_counter])\n",
    "            title_counter +=1\n",
    "                \n",
    "                \n",
    "            # set legend\n",
    "            ax[index_var, 0].legend(\n",
    "                custom_lines, \n",
    "                ['random sequence', 'AL sequence'], \n",
    "                loc=\"best\", \n",
    "                frameon=False\n",
    "            )\n",
    "            ax[index_var, 1].legend(\n",
    "                custom_lines, \n",
    "                ['random sequence', 'AL sequence'], \n",
    "                loc=\"best\", \n",
    "                frameon=False\n",
    "            )\n",
    "                \n",
    "        # set x-axis\n",
    "        ax[index_var, 0].set_xlabel(\n",
    "            'epoch', \n",
    "            fontsize=FONTSIZE+3\n",
    "        )\n",
    "        ax[index_var, 1].set_xlabel(\n",
    "            'epoch', \n",
    "            fontsize=FONTSIZE+3\n",
    "        )\n",
    "            \n",
    "        # set column titles\n",
    "        cols = [\n",
    "            'Validation losses with δ=1 \\n a.', \n",
    "            'Validation losses with δ=0 \\n b.'\n",
    "        ]\n",
    "        for axes, col in zip(ax[0], cols):\n",
    "            axes.set_title(col)\n",
    "\n",
    "\n",
    "    # create saving paths \n",
    "    saving_path_valup0 = (\n",
    "        path_to_saving_seqimportance \n",
    "        + pred_type\n",
    "        + ' valup0.pdf'\n",
    "    )\n",
    "\n",
    "    saving_path_valup1 = (\n",
    "        path_to_saving_seqimportance \n",
    "        + pred_type \n",
    "        + ' valup1.pdf'\n",
    "    )\n",
    "\n",
    "    # set layout tight\n",
    "    fig_valup0.tight_layout()\n",
    "    fig_valup1.tight_layout()\n",
    "\n",
    "    # save figures\n",
    "    fig_valup0.savefig(saving_path_valup0)\n",
    "    fig_valup1.savefig(saving_path_valup1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Exemplar predictions\n",
    "\n",
    "For each experiment, we have saved a sample of 1,000 randomly chosen data points that were not queried by our passive learning or active learning algorithm when these terminated. Here, we loadfive exemplar points for each of our conducted experiments from these at random and compare the prediction of each of our three models. The first column represents the performance of the initial model prior to being further trained on any data from the candidate data pool. The second column represents the performance of our passively trained benchmark model. The third column represents the performance of our actively trained prediction model.\n",
    "\n",
    "What we ideally want to observe visually is that the prediction performance of our actively trained models is approximately as good as the performance of our passively trained models, as we are able to use fewer data points and sensors with our active learning models. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%capture \n",
    "# prevents figures being printed out if used at begining of cell\n",
    "\n",
    "# choose how many random datapoints to predict and plot\n",
    "N_DATAPOINTS = 5\n",
    "\n",
    "# number of columns to plot data points. Keep this 3\n",
    "n_cols = 3\n",
    "\n",
    "# choose a different font size for these figures\n",
    "FONTSIZE = 14\n",
    "\n",
    "# set the fontsize\n",
    "mpl.rcParams.update({'font.size': FONTSIZE})\n",
    "\n",
    "# iterate over all considered prediction types\n",
    "for index_pred, pred_type in enumerate(PRED_TYPE_LIST):\n",
    "    \n",
    "    # iterate over all considered parameter constellations\n",
    "    for index_param, parameter in enumerate(PARAMETER_LIST):\n",
    "  \n",
    "        delta = int(parameter[5])\n",
    "        valup = int(parameter[12]) \n",
    "\n",
    "        # provide paths to initial and PL models and samples\n",
    "        path_to_initial_model = (\n",
    "            path_to_models \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + initial_model_filename\n",
    "        )\n",
    "        path_to_PL_model = (\n",
    "            path_to_models \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type \n",
    "            + '/' \n",
    "            + PL_model_filename\n",
    "        )\n",
    "        path_to_PL_data = (\n",
    "            path_to_samples \n",
    "            + parameter \n",
    "            + '/' \n",
    "            + pred_type\n",
    "            + '/' \n",
    "            + 'PL_'\n",
    "        )\n",
    "        \n",
    "        # import models and samples for PL\n",
    "        initial_model =  tf.keras.models.load_model(\n",
    "            path_to_initial_model, \n",
    "            compile=False\n",
    "        )\n",
    "        PL_model = tf.keras.models.load_model(\n",
    "            path_to_PL_model, \n",
    "            compile=False\n",
    "        )\n",
    "        \n",
    "        path_to_file = path_to_PL_data + 'X_t.npy' \n",
    "        X_t = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_s.npy' \n",
    "        X_s = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_s1.npy' \n",
    "        X_s1 = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'X_st.npy' \n",
    "        X_st = np.load(path_to_file)\n",
    "\n",
    "        path_to_file = path_to_PL_data + 'Y.npy' \n",
    "        Y_pl = np.load(path_to_file)\n",
    "        \n",
    "        # make predictions\n",
    "        initial_predictions = initial_model.predict(\n",
    "            [X_t, X_s1, X_st]\n",
    "        )\n",
    "        PL_predictions = PL_model.predict(\n",
    "            [X_t, X_s1, X_st]\n",
    "        )\n",
    "\n",
    "        # iterate over all AL variables\n",
    "        for index_var, AL_variable in enumerate(AL_VARIABLES):\n",
    "            \n",
    "            # iterate over all AL variants\n",
    "            for index_method, AL_variant in enumerate(AL_VARIANTS):\n",
    "                \n",
    "                # create figure\n",
    "                fig, ax = plt.subplots(\n",
    "                    N_DATAPOINTS, \n",
    "                    n_cols, \n",
    "                    sharex=True , \n",
    "                    figsize=(16, N_DATAPOINTS * 4)\n",
    "                )\n",
    "\n",
    "                AL_model_filename = '{} {}.h5'.format(\n",
    "                    AL_variable, \n",
    "                    AL_variant\n",
    "                )\n",
    "                AL_sample_name = '{} {} '.format(\n",
    "                    AL_variable, \n",
    "                    AL_variant\n",
    "                )\n",
    "                \n",
    "                # provide paths to initial and PL models and samples\n",
    "                path_to_AL_model = (\n",
    "                    path_to_models \n",
    "                    + parameter \n",
    "                    + '/' \n",
    "                    + pred_type \n",
    "                    + '/' \n",
    "                    + AL_model_filename\n",
    "                )\n",
    "                path_to_AL_data = (\n",
    "                    path_to_samples \n",
    "                    + parameter \n",
    "                    + '/' \n",
    "                    + pred_type \n",
    "                    + '/' \n",
    "                    + AL_sample_name\n",
    "                )\n",
    "                \n",
    "                \n",
    "                # import models and samples for AL\n",
    "                AL_model =  tf.keras.models.load_model(\n",
    "                    path_to_AL_model, \n",
    "                    compile=False\n",
    "                )\n",
    "        \n",
    "                path_to_file = path_to_AL_data + 'X_t.npy' \n",
    "                X_t = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_s.npy' \n",
    "                X_s = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_s1.npy' \n",
    "                X_s1 = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'X_st.npy' \n",
    "                X_st = np.load(path_to_file)\n",
    "\n",
    "                path_to_file = path_to_AL_data + 'Y.npy' \n",
    "                Y_al = np.load(path_to_file)\n",
    "                \n",
    "                # make predictions\n",
    "                AL_predictions = AL_model.predict(\n",
    "                    [X_t, X_s1, X_st]\n",
    "                )\n",
    "                \n",
    "                # plot predictions for randomly chosen points\n",
    "                rnd_index_array_initial = np.random.choice(\n",
    "                    np.arange(len(Y_pl)),\n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "                rnd_index_array_PL = np.random.choice(\n",
    "                    np.arange(len(Y_pl)),\n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "                rnd_index_array_AL = np.random.choice(\n",
    "                    np.arange(len(Y_al)), \n",
    "                    N_DATAPOINTS\n",
    "                )\n",
    "\n",
    "                title_counter = 0\n",
    "                \n",
    "                # iterate over each row of figure\n",
    "                for row in range(N_DATAPOINTS):\n",
    "                    \n",
    "                    plot1 = ax[row, 0].plot(\n",
    "                        initial_predictions[\n",
    "                            rnd_index_array_initial[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 1].plot(\n",
    "                        PL_predictions[\n",
    "                            rnd_index_array_PL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 2].plot(\n",
    "                        AL_predictions[\n",
    "                            rnd_index_array_AL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    plot2 = ax[row, 0].plot(\n",
    "                        Y_pl[\n",
    "                            rnd_index_array_initial[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 1].plot(\n",
    "                        Y_pl[\n",
    "                            rnd_index_array_PL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    ax[row, 2].plot(\n",
    "                        Y_al[\n",
    "                            rnd_index_array_AL[\n",
    "                                row\n",
    "                            ]\n",
    "                        ]\n",
    "                    )\n",
    "                    \n",
    "                    # set title\n",
    "                    for col in range(n_cols):\n",
    "                        ax[row, col].set_title(fig_title_list[title_counter])\n",
    "                        title_counter +=1\n",
    "                \n",
    "                # add a figure legend\n",
    "                fig.legend(\n",
    "                    [plot1, plot2], \n",
    "                    labels=['true load profile', 'predicted load profile'], \n",
    "                    loc='upper center', \n",
    "                    bbox_to_anchor=(0.8, 0.95)\n",
    "                )\n",
    "\n",
    "                colname_list = [\n",
    "                    'Initial model \\n a.', \n",
    "                    'Passive learning \\n b.', \n",
    "                    'Active learning \\n c.'\n",
    "                ]\n",
    "\n",
    "                # set col names\n",
    "                for axes, colname in zip(ax[0], colname_list):\n",
    "                    axes.set_title(colname)\n",
    "\n",
    "                # set one y- and x-axis for all sub plots\n",
    "                fig.add_subplot(111, frame_on=False)\n",
    "                plt.tick_params(\n",
    "                    labelcolor=\"none\", \n",
    "                    bottom=False, \n",
    "                    left=False\n",
    "                )\n",
    "                plt.xlabel(\n",
    "                    'time [15-min]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                plt.ylabel(\n",
    "                    'building electric consumption [kW]', \n",
    "                    fontsize=FONTSIZE+3\n",
    "                )\n",
    "                \n",
    "                \n",
    "                filename = '{} {} {} delta{} valup{}.pdf'.format(\n",
    "                    pred_type, \n",
    "                    AL_variable, \n",
    "                    AL_variant, \n",
    "                    delta, \n",
    "                    valup\n",
    "                )\n",
    "\n",
    "                saving_path = (\n",
    "                    path_to_exemplar_predictions \n",
    "                    + filename\n",
    "                )\n",
    "\n",
    "                fig.savefig(saving_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
